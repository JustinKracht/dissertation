# Introduction {#intro}

Covariance structure models (also called structural equation models) are widely used in psychological research [@bollen1989]. These models allow a structured covariance matrix to be represented as a matrix-valued function of a vector of parameters such that $\bm{\Omega}= \bm{\Omega}(\bm{\gamma})$, where $\bm{\Omega}$ is a $p \times p$ covariance matrix and $\bm{\gamma}$ is a vector of $h$ free model parameters. Stated another way, covariance structure models attempt to represent the structural connections between a set of unobserved latent variables (factors) and a set of observed variables that are indicators of the latent variables. When assessing model fit or estimating the dispersion of the estimated structural parameters, $\hat{\bm{\gamma}}$, researchers traditionally assume that the model holds perfectly in the population. It is assumed that there exists some vector $\bm{\gamma} = \bm{\gamma}_0$ such that the population covariance matrix $\bm{\Omega}$ can be perfectly reproduced (i.e., $\bm{\Omega} = \bm{\Omega}(\bm{\gamma}_0)$). If the model fits perfectly in the population, differences between the sample covariance matrix and the corresponding model-implied covariance matrix can only be due to sampling variability. 

However, the assumption that the covariance structure is correctly specified in the population will nearly always be violated in practice [@maccallum1991; @maccallum2001; @browne2002; @meehl2002; @cudeck1991; @tomarken2003]. After all, "no mathematical model will fit real-world phenomena exactly" [@maccallum2001, p. 503] due, for example, to non-linearities in the relationships between factors and indicators, or to the effect of numerous minor factors of little theoretical interest [@cudeck1992]. The idea that all models are imperfect representations of reality has been expressed many ways, perhaps most succinctly by Box's aphorism that "all models are wrong, but some are useful" [-@box1987, p. 424]. Further interesting discussions of the idea that models are only useful approximations of reality (and are often useful *because* they are approximations) can be found in both scientific and popular literature [@carroll1894; @eco1994; @borges1998; @gelman2008; @steele2008; @nester1996].

Recognizing that all models are literally false, and thus no covariance structure model will fit perfectly in the population, several authors have suggested that estimation error for these models can be attributed to two sources: error due to sampling variability and error due to model misfit [@tucker1969; @cudeck1991; @browne1992]. This second type of error has been variously referred to as *model error* [@tucker1967evaluation; @tucker1969; @maccallum2001], *error of approximation* [@cudeck1991], *specification error* [@satorra2015], or *adventitious error* [@wu2015]. Although some of these terms are related to specific views regarding the nature of model error [c.f. @wu2015; @tucker1969], all of the terms refer to the discrepancy between the model-implied covariance matrix, $\bm{\Omega}$, and the error-perturbed population covariance matrix, $\bm{\Sigma} = \bm{\Omega} + \mathbf{E}$ (where $\mathbf{E}$ is a symmetric matrix representing the effects of model error). In this proposal, the term "model error" will generally be used to describe the discrepancy between $\bm{\Sigma}$ and $\bm{\Omega}$.

Acknowledging model error is important because it can have significant implications for estimating covariance structure models. For instance, consider the traditional Chi-square test of exact model fit. Given a sample covariance matrix $\mathbf{S}$, the minimum objective function value for a hypothesized model $\hat{F} = F(\mathbf{S}, \bm{\Omega}(\hat{\bm{\gamma}}))$ obtained by minimizing a discrepancy function $F(\mathbf{S}, \bm{\Omega}(\bm{\gamma}))$ is assumed to follow a central Chi-square distribution when multiplied by $N - 1$, where $N$ denotes the sample size [@olsson2004].[^ml-vs-ols] However, the test requires two stringent assumptions that are unlikely to both be satisfied in empirical settings: (a) that the observed variables are multivariate normal, and (b) that the model fits perfectly in the population [i.e., there is no model error\; @browne1984]. If (b) is not satisfied, then the test statistic $n \hat{F}$ will not follow a central Chi-square distribution and will lead to incorrect tests [@olsson2004]. Moreover, Chi-square tests of exact fit are sensitive to sample size, with large sample sizes leading to almost certain rejection of the model, even with small amounts of misspecification [@yuan2004; @bentler1980; @tomarken2003]. In any case, testing a model that is known not to be perfectly true against the null hypothesis of perfect fit would seem to have limited usefulness [@browne1992; @steiger2007]. 

[^ml-vs-ols]: The maximum likelihood discrepancy function is commonly used, but other common discrepancy functions (e.g., generalized least squares, weighted least squares, asymptotically distribution free) will converge to the same minimum discrepancy values when the model is correctly specified and the observed variables are multivariate normal [@olsson2004].

Model error also has implications for covariance structure modeling beyond global tests of model fit. For instance, traditional methods of computing confidence intervals for model parameters assume that all error is sampling error (i.e., the model fits perfectly in the population). Thus, confidence intervals produced using these methods are overly-optimistic when model error is present [@wu2015]. Simulation studies have shown that the presence of model error can also impact parameter estimation for exploratory factor analysis [@briggs2003], dimensionality identification [@kracht2022], the behavior of confidence regions and fungible parameter estimates for structural equation models [@pek2012], and is important in other contexts as well [@trichtinger2020; @beauducel2016; @dewinter2016; @gnambs2016; @hsu2015].

These simulation studies represent a recent trend toward incorporating model error in Monte Carlo simulation studies involving covariance structure models. Including model error in these studies is important for at least two reasons. First, the addition of model error makes simulated data sets more representative of empirical data sets, which almost certainly do not have population covariance matrices that are perfectly fit by any simple covariance structure model. Therefore, the inclusion of model error should lead to results that are more generalizable to empirical settings compared to Monte Carlo studies that do not include model error. Second, incorporating model error allows researchers to evaluate the robustness of methods when covariance structure models do not hold exactly.

Recognizing the importance of incorporating model error in Monte Carlo simulation studies, various authors have introduced methods for generating population covariance matrices with imperfect model fit. The three most popular of these methods were proposed by (a) Tucker, Koopman, and Linn [TKL\; -@tucker1969], (b) Cudeck and Browne [CB\; -@cudeck1992], and (c) Wu and Browne [WB\; -@wu2015].

## Model-Error Methods

### The Tucker, Koopman, and Linn Method {#tkl-method}

One of the first model-error methods was developed by @tucker1969 in the context of common factor analysis. The common factor analysis model in terms of $p$ manifest variables and $k$ common factors can be written as

\begin{equation}
\bm{\Omega} = \bm{\Lambda}\bm{\Phi}\bm{\Lambda}^\prime + \bm{\Psi},
(\#eq:cfm)
\end{equation}

\noindent where $\bm{\Omega}$ is the model-implied $p \times p$ covariance matrix, $\bm{\Lambda}$ is the $p \times k$ factor-pattern matrix, $\bm{\Phi}$ is the $k \times k$ common factor covariance matrix, and $\bm{\Psi}$ is the $p \times p$ diagonal matrix containing the uniqueness variances. For convenience, we can define all observed variables and common factors as having means of zero and standard deviations of one so that $\bm{\Omega}$ has a unit diagonal (i.e., is a correlation matrix). @tucker1969 proposed extending the common factor model to include many minor common factors of small effect in addition to the major common factors to represent "unsystematic or unknown aspects of the process that generates the data" [@cudeck1992, p. 358]. The model they proposed can be written as

\begin{equation}
\bm{\Sigma} = \bm{\Lambda}\bm{\Phi}\bm{\Lambda}^\prime + \bm{\Psi} + \mathbf{WW}^\prime,
(\#eq:cfm-tkl)
\end{equation}

\noindent where $\bm{\Sigma}$ is the $p \times p$ error-perturbed population covariance matrix, $\mathbf{W}$ is the $p \times q$ ($q \gg k$) matrix of minor common factor loadings, and all other terms are as previously defined. For convenience, we can define the observed variables to be in standard score form such that $\bm{\Sigma}$ has a unit diagonal. The combined influence of the $q$ minor common factors represents the reliable common variance (and covariance) not accounted for by the major common factors and is considered to be due to model error. Although @tucker1969 do not give a specific recommendation for the number of minor common factors to incorporate, values of $q$ between 50 and 150 are common [@kracht2022; @trichtinger2020; @briggs2003; @jung2008regularized; @cai2013].

When using the TKL method, it is common to specify the amount of model error to include as the proportion of the uniqueness factor variances, or "uniqueness variances", that is reapportioned to the minor common factors. The proportion of the uniqueness variances that is reapportioned and how that variance is distributed among the minor common factors are determined by two user-specified parameters, $\nu_{\textrm{e}} \in [0,1]$ and $\epsilon \in [0,1]$, respectively. To create the matrix of minor factor loadings ($\mathbf{W}$), a $p \times q$ provisional matrix, $\mathbf{W}^*$, is first created such that the $i$th column of $\mathbf{W}^*$ ($i \in [1..q]$)[^integer-range-notation] consists of $p$ independent samples from $\mathcal{N}(0, (1 - \epsilon)^{2(i-1)})$, where $\mathcal{N}(0, (1 - \epsilon)^{2(i-1)})$ denotes a normal distribution with a mean of zero and a variance of $(1 - \epsilon)^{2(i-1)}$. Because the standard deviation of the $i$th column of $\mathbf{W}^*$ is given by $(1 - \epsilon)^{i - 1}$, values of $\epsilon$ close to zero result in columns with relatively equal variance, corresponding to approximately equipotent minor factors. On the other hand, values of $\epsilon$ close to one result in error variance primarily being distributed to the first minor factor, with the remaining variance distributed to the other minor factors in a decreasing geometric sequence. 

[^integer-range-notation]: When $a$ and $b$ are integers, the notation $[a..b]$ is used here to denote the interval of integers between $a$ and $b$, inclusive.

To ensure that the minor common factors account for the specified proportion of uniqueness variance ($\nu_{\textrm{e}}$), $\mathbf{W}^*$ is then scaled to create $\mathbf{W}$. This scaling is done in several steps. First, a $p \times p$ diagonal matrix $\bm{\Psi}^*$ is created such that

\begin{equation}
\bm{\Psi}^* = \mathbf{I}_p - \dg(\bm{\Lambda} \bm{\Phi} \bm{\Lambda}^\prime),
(\#eq:psi-star)
\end{equation} 

\noindent where $\dg(\bm{\Lambda}\bm{\Phi}\bm{\Lambda}^\prime)$ is the diagonal matrix formed from the diagonal entries in $\bm{\Lambda}\bm{\Phi}\bm{\Lambda}^\prime$ and $\mathbf{I}_p$ denotes a $p \times p$ identity matrix. Then the matrix $\mathbf{W}$ is formed using

\begin{equation}
\mathbf{W} = (\dg(\mathbf{W}^* \mathbf{W}^{* \prime})^{-1} \bm{\Psi}^* \nu_{\textrm{e}})^{1/2} \mathbf{W}^*.
(\#eq:W-matrix)
\end{equation}

\noindent This process ensures that the $q$ minor common factors account for the specified proportion of the variance not accounted for by the major common factors. The $\mathbf{W}$ matrix can then be used to create the diagonal matrix of unique variances, $\bm{\Psi} = \mathbf{I}_p - \dg(\bm{\Lambda} \bm{\Phi}\bm{\Lambda}^\prime + \mathbf{WW}^\prime)$. The $\bm{\Lambda}$, $\bm{\Psi}$, and $\mathbf{W}$ matrices are then used to construct the population correlation matrix (with model error), $\bm{\Sigma}$, as shown in \autoref{eq:cfm-tkl}. The TKL method is one of the most widely-used methods for generating correlation matrices with imperfect model fit [@lorenzo-seva2020; @kracht2022; @chung2019; @beauducel2016; @lorenzo-seva2016; @dewinter2016; @gnambs2016; @myers2015a].[^1] 

[^1]: @tucker1969 was cited 204 times as of July 28, 2022, according to citation counts provided by Web of Science.

Although the original TKL method is still most commonly used in simulation studies, at least two variants of this method have since been developed. First, @hong1999 introduced a variation of the TKL method that allowed for minor common factors that were correlated with each other and with the major common factors. In Hong's model, the population covariance matrix can be written as

\begin{equation}
\bm{\Sigma} = \mathbf{L} \mathbf{C} \mathbf{L}^\prime + \bm{\Psi},
\end{equation}

\noindent where $\mathbf{L} = \begin{bmatrix} \bm{\Lambda} & \mathbf{W} \end{bmatrix}$ is the super matrix containing the major and minor factor loadings, and $\bm{\Psi}$ is the diagonal matrix of uniqueness variances, as defined in \autoref{eq:cfm}. The matrix $\mathbf{C}$ is the correlation matrix for the major and minor factors such that

\begin{equation}
\mathbf{C} = \begin{bmatrix} \bm{\Phi} & \bm{\Upsilon} \\ \bm{\Upsilon}^\prime & \bm{\Gamma} \end{bmatrix},
\end{equation}

\noindent where $\bm{\Phi}$ is the $k \times k$ major factor correlation matrix, $\bm{\Upsilon}$ is the $k \times q$ matrix of correlations between the major and minor factors, and $\bm{\Gamma}$ is the $q \times q$ minor factor correlation matrix.

Hong's [-@hong1999] article has been cited a number of times since its publication[^2], but only one published study has applied Hong's method [@porritt2015]. In Porritt's [-@porritt2015] simulation study, all major and minor factor correlations were fixed at .3, following the example given by Hong [-@hong1999]. However, neither Porritt [-@porritt2015] nor Hong [-@hong1999] directly compared Hong's method with the original TKL method. Therefore, it remains unclear whether modeling major-minor factor correlations is important when simulating covariance matrices with model error.

[^2]: @hong1999 was cited twelve times as of March 11, 2021, according to Web of Science.

A second variant of the TKL method was recently introduced by Trichtinger and Zhang [-@trichtinger2020]. Specifically, Trichtinger and Zhang's method adapted the TKL method to allow the simulation of covariance matrices with model error for multivariate time series data. Trichtinger and Zhang [-@trichtinger2020] first introduced a novel test statistic appropriate for P-technique factor analysis [@cattell1947]. They then used their adapted TKL method to generate data with model error in a Monte Carlo simulation study to evaluate the empirical characteristics of their test statistic. Although their adapted TKL method has not yet been used in any other published simulation studies, it demonstrates that it is possible to extend the TKL method beyond the simple common factor model to other types of covariance structure models.

### The Cudeck and Browne (CB; 1992) Method {#cb}

An alternative to the TKL method for modeling imperfect model fit in simulation studies was described by Cudeck and Browne [-@cudeck1992]. These authors agreed with @tucker1969 that no simple factor analysis model is likely to fit exactly in the population and that Monte Carlo simulation studies conducted to evaluate statistical methods should incorporate model error to test robustness against imperfect model fit. However, Cudeck and Browne wanted a model-error method that was more flexible than the TKL method and that allowed the user to specify the desired discrepancy function value to control the amount of model error. Therefore, Cudeck and Browne proposed a new method of generating data from models with imperfect fit, building on the work of @tucker1969. They developed their new approach to satisfy three desiderata: First, that the approach is general to covariance structure models and not only factor analysis models; Second, that the approach allows the pre-specification of the amount of model error in terms of the maximum likelihood or least squares discrepancy function value, $F(\bm{\Sigma}, \bm{\Omega}(\bm{\gamma})) = \delta$; Third, that the minimizer of the discrepancy function is a specified vector of model parameters, $\bm{\gamma} = \bm{\gamma_0}$. 

The Cudeck and Browne method (referred to as CB hereafter) works as follows. A $p \times p$ population covariance matrix is defined as the sum

\begin{equation}
\bm{\Sigma} = \bm{\Omega}(\bm{\gamma}) + \mathbf{E},
(\#eq:cb)
\end{equation}

\noindent where $\bm{\Omega}(\bm{\gamma})$ is a matrix-valued function of a vector of parameters, $\bm{\gamma}$, and $\mathbf{E}$ is a $p \times p$ symmetric matrix such that \autoref{eq:cb} is positive definite. Moreover, let $\bm{\Sigma}_0 = \bm{\Omega}(\bm{\gamma}_0) + \mathbf{E}$ be the population covariance matrix for a particular vector of model parameters, $\bm{\gamma}_0$. The CB method works by finding an $\mathbf{E}$ matrix such that the discrepancy function $F(\bm{\Sigma}_0, \bm{\Omega}(\bm{\gamma}_0))$ is minimized at $\bm{\gamma}_0$ and the minimum is equal to a pre-specified value, $\delta$. Cudeck and Browne (1992) considered discrepancy functions of the form

\begin{equation}
F(\bm{\Sigma}, \bm{\Omega}(\bm{\gamma})) = \frac{1}{2} \tr [\mathbf{Z}^{-1}(\bm{\Sigma} - \bm{\Omega}(\bm{\gamma}))^2],
(\#eq:disc-fun)
\end{equation}

\noindent where the fixed $p \times p$ matrix $\mathbf{Z}$ does not depend on $\mathbf{E}$. Note that when $\mathbf{Z} = \mathbf{I}_p$, \autoref{eq:disc-fun} is the discrepancy function for ordinary least squares. The discrepancy function for ordinary-theory maximum likelihood can be written as

\begin{equation}
F_{\textrm{ML}}(\bm{\Sigma}, \bm{\Omega}(\bm{\gamma})) = \ln |\bm{\Omega}(\bm{\gamma})| - \ln |\bm{\Sigma}| + \tr [\bm{\Sigma} \bm{\Omega}(\bm{\gamma})^{-1}] - p,
(\#eq:disc-ml)
\end{equation}

\noindent where $|\bm{\Sigma}|$ is the determinant of $\bm{\Sigma}$. Cudeck and Browne [-@cudeck1992] showed that the minimizer of \autoref{eq:disc-fun} is the same as the minimizer of \autoref{eq:disc-ml} when $\mathbf{Z} = \bm{\Omega}(\bm{\gamma}_{\textrm{ML}})$, where $\bm{\gamma}_{\textrm{ML}}$ is the minimizer of the maximum likelihood discrepancy function in \autoref{eq:disc-ml}. Thus, \autoref{eq:disc-fun} is a general form of the discrepancy function that is equivalent to either the least squares discrepancy function or the maximum likelihood discrepancy function, depending on the value of $\mathbf{Z}$. 

Recall that one objective of the CB method is to ensure that the discrepancy function $F(\bm{\Sigma}_0, \bm{\Omega}(\bm{\gamma}))$ is minimized when $\bm{\gamma} = \bm{\gamma}_0$. To do this, it is necessary to find an $\mathbf{E}$ matrix such that the gradient $\partial F(\bm{\Sigma}_0, \bm{\Omega}(\bm{\gamma})) / \partial \bm{\gamma} = \bm{0}$. Cudeck and Browne [-@cudeck1992] showed the gradient can be written as

\begin{equation}
\frac{\partial F(\bm{\Sigma}_0, \bm{\Omega}(\bm{\gamma}))}{\partial \bm{\gamma}} = \mathbf{B}^\prime \tilde{\mathbf{e}}
(\#eq:gradient-of-F)
\end{equation}

\noindent where $\tilde{\mathbf{e}} = \textrm{vecs} \: [ \bm{\Sigma}_0 - \bm{\Omega}(\bm{\gamma}) ]$ is a $p^* \times 1$ vector, $p^* = \frac{1}{2}(p^2 + p)$. The $\vecs$ operator is defined such that for a symmetric matrix, $\mathbf{A}$, $\vecs \mathbf{A} = \begin{bmatrix} a_{11} & a_{12} & a_{22} & a_{13} & \dots & a_{pp} \end{bmatrix}^\prime$. Put another way, the $\vecs \mathbf{A}$ operator returns a vector of the stacked upper-diagonal elements of $\mathbf{A}$ (including the diagonal). Additionally, $\mathbf{B}$ is a $p^* \times h$ matrix (where $h$ is the number of free model parameters contained in $\bm{\gamma}$) that depends on both $\mathbf{Z}$ and the derivative of $\bOmega(\bm{\gamma})$ with respect to the $i$th element of $\bm{\gamma}$, $\dot{\bm{\Omega}}_i = [\partial \bm{\Omega}(\bm{\gamma})/ \partial \gamma_i]$. Specifically, the $i$th column of $\mathbf{B}$, $\mathbf{b}_i$, is constructed such that $\mathbf{b}_i = - \mathbf{D} \vecs (\mathbf{Z}^{-1} \dot{\bm{\Omega}}_i \mathbf{Z}^{-1})$, where $\mathbf{D}$ is a $p^* \times p^*$ diagonal matrix with diagonal elements formed by the vector $\begin{bmatrix} 1 & 2 & 1 & 1 & 2 & 1 & \dots & 1 \end{bmatrix}^\prime$ with elements equal to 1 if the corresponding element of $\vecs \bOmega$ is a diagonal element of $\bOmega$ and 2 otherwise.

With the gradient written in the form given in \autoref{eq:gradient-of-F}, it can be set equal to the null vector, $\mathbf{B}^\prime \mathbf{\tilde{e}} = \bm{0} |_{\bm{\gamma = \bm{\gamma}_0}}$ and solved for $\tilde{\mathbf{e}} = \vecs \tilde{\mathbf{E}}$. To find a suitable $\mathbf{\tilde{e}}$, let $\mathbf{y}$ be a non-null $\frac{1}{2}(p^2 + p) \times 1$ vector. Then the difference $\mathbf{\tilde{e}} = \mathbf{y} - \mathbf{B(\mathbf{B}^\prime \mathbf{B})^{-1} \mathbf{B}^\prime \mathbf{y}}$ gives an $\mathbf{\tilde{e}}$ vector such that 

\begin{equation}
\mathbf{B}^\prime \mathbf{\tilde{e}} = \bm{0} |_{\bm{\gamma = \bm{\gamma}_0}}. 
(\#eq:proj-y-on-B)
\end{equation}

\noindent In plain language, $\mathbf{\tilde{e}}$ is the residual vector between $\mathbf{y}$ and the projection of $\mathbf{y}$ onto the column space of $\mathbf{B}$ given by $\mathbf{B(\mathbf{B}^\prime \mathbf{B})^{-1} \mathbf{B}^\prime \mathbf{y}}$. This residual vector is orthogonal to the column space of $\mathbf{B}$ [@strang2016, p. 208], so \autoref{eq:proj-y-on-B} is satisfied. Note that the $\mathbf{y}$ vector is arbitrary and that different $\mathbf{y}$ vectors correspond to different $\tilde{\mathbf{e}}$ values.[^ml-vs-ols-y-choice]

[^ml-vs-ols-y-choice]: According to Cudeck and Browne [-@cudeck1992], $\mathbf{y}$ is arbitrary when maximum likelihood is used, but must be chosen more carefully when OLS is used to avoid indefinite solutions.

After finding $\tilde{\mathbf{e}}$ (and correspondingly, $\tilde{\mathbf{E}}$) such that $F(\bm{\Sigma}_0, \bm{\Omega}(\bm{\gamma}))$ is minimized at $\bm{\gamma} = \bm{\gamma}_0$, the next step is to ensure that the minimum is equal to a specified value, $\delta$. The population Root Mean Square Error of Approximation [RMSEA\; @steiger1990] value is related to the objective function value by $\varepsilon = \sqrt{F(\bm{\Sigma}_0, \bm{\Omega}(\bm{\gamma}))/df}$, where $\varepsilon$ and $df$ denote the RMSEA and model degrees of freedom, respectively. Therefore, $\delta$ is generally selected to produced a desired RMSEA value such that $\delta = \varepsilon^2 df$. Cudeck and Browne defined the error matrix as $\mathbf{E} = \kappa \tilde{\mathbf{E}}$, where $\kappa$ is a scaling term that is chosen so that the value of the objective function at its minimum is equal to $\delta$. When $\kappa = 0$, $\bm{\Sigma} = \bm{\Omega}$, whereas larger values of $\kappa$ lead to larger discrepancy function values. Cudeck and Browne (1992) furthermore proved that $\bm{\gamma}_0$ is the global minimizer of $F(\bm{\Sigma}_0, \bm{\Omega}(\bm{\gamma}))$ as long as $\kappa$ is not too large (pp. 360--361). Thus, their second desideratum (i.e., that $\bm{\gamma}_0$ be the minimizer of the objective function) and third desideratum (i.e., that the value of the discrepancy function at its minimum is $\delta$) are both satisfied.

The CB method is appealing for use in simulation studies for a number of reasons. First, it allows the user to specify a desired RMSEA value. Second, unlike the TKL method, the CB method does not have any tuning parameters that need to be chosen (other than the target RMSEA). Third, the CB method is easily extendable to many types of covariance structure models. Likely because of these advantages, the CB method has been used in a relatively large number of Monte Carlo simulation studies [@lai2017; @lai2018; @lai2019a; @lai2020; @lai2020b; @lai2020a; @lai2020c; @montoya2020; @xia2021].

Although it is appealing for simulation work, the CB method carries with it an assumption about the nature of model error that might or might not be considered reasonable for empirical data sets. Recall that a requirement of the CB method is that the discrepancy function $F(\bm{\Sigma}_0, \bm{\Omega}(\bm{\gamma}_0))$ is minimized when $\bm{\gamma} = \bm{\gamma}_0$. When a model is mis-specified, there does not exist any $\bm{\gamma}_0$ such that $\bm{\Sigma}_0 = \bm{\Omega}(\bm{\gamma}_0)$. However, the maximum likelihood parameter estimate $\hat{\bm{\gamma}}_{\textrm{ML}}$ is still consistent toward the minimizer of the maximum likelihood discrepancy function under mild regularity conditions [@wu2015; @shapiro1983, Theorem 5.4; @shapiro2007, Section 5.3]. Moreover, if a sample covariance matrix $\mathbf{S}$ is an unbiased estimator of $\bm{\Sigma}_0$, then the expected value of $\mathbf{S}$ is $\bm{\Sigma}_0$. Taken together, these properties indicate that maximum likelihood parameter estimates converges to $\bm{\gamma}_0$ as $N \to \infty$ under the CB framework. 

This result reflects the view that the "true" population parameter values are simply the parameter values obtained by fitting a model to $\bm{\Sigma}$ using a particular discrepancy function. In this view, the discrepancy between the $\bm{\Sigma}$ and the model-implied covariance matrix obtained from analyzing $\bm{\Sigma}$ (i.e., $\hat{\bm{\Omega}}$) is of primary interest, not the discrepancy between $\bm{\Sigma}$ and the implied covariance matrix for some ideal model ($\bm{\Omega}$). Because the CB method ensures that $\bm{\gamma}_0$ is a minimizer of the discrepancy function, $\hat{\bm{\Omega}} = \bm{\Omega}$. Thus, in this view it makes sense that the population parameters ($\bm{\gamma}_0$) will be perfectly recovered as $N \to \infty$.

### The Wu and Browne (WB; 2015) Method

A third model-error method was introduced by Wu and Browne [-@wu2015] and is unique among the three approaches because it represents model error as a random effect rather than as a fixed quantity. Moreover, the TKL and CB model-error methods were developed for use in simulation studies. In contrast, the WB method was motivated by Wu and Browne's development of a method for estimating confidence intervals for model parameters, taking into account variability due to model error.

Before describing Wu and Browne's [-@wu2015] estimation method, it will be useful to define two important terms. The term *model discrepancy*, as used by Wu and Browne [-@wu2015], corresponds to what has been previously referred to as model error (i.e., the difference between the error-perturbed and model-implied population covariance matrices). The term *adventitious error* is used to describe the process underlying model discrepancy [@wu2015]. In Wu and Browne's [-@wu2015] conceptualization, model discrepancy arises from differences between two populations: an operational population from which the observed sample is representative, and a theoretical general population. The theory (as represented by the covariance structure model) is hypothesized to hold exactly in the theoretical general population, but not in the operational population [@wu2015; @wu2015a]. The general population might also be referred to as the *ideal* population. This is not the terminology used by Wu and Browne [-@wu2015], but more clearly reflects their view of the general population as being "...contained in the Platonic Aether" [attributed to Michael C. Edwards in @wu2015a, p. 620] as opposed to "a mundane collection of people that can be reached through more complicated designs" [@wu2015a, p. 621].

To illustrate their conception of adventitious error, Wu and Browne [-@wu2015] give the hypothetical example of researchers who are interested in validating the structure of a depression scale hypothesized to hold for all U.S. adults under some general measurement condition. The researchers attempt to validate the hypothesized structure by randomly selecting adults in Chicago on some particular summer day. Thus, the operational population (adults in Chicago on a particular day) differs from the theoretical general (or ideal) population. It is the difference between these two populations that Wu and Browne call adventitious error. In a follow-up article, Wu and Browne [-@wu2015a] clarify that adventitious error is not simply an issue of sub-populations that might be resolved by using alternative models or designs. They state:

> Although we believe that the theoretical population is an ideal in nature, we are not critical of it. Instead, we maintain that, just like statistical models, it is a construction by the human mind in order to understand the world and is necessarily a simplified description of the reality. The usefulness of the concept of a general population lies in its explanatory power but not in its tangible existence as a group of people or a set of measurement outcomes [@wu2015a, p. 619].

Building upon this view, Wu and Browne [-@wu2015] argued that the discrepancy between the operational and ideal population models is a source of variation that is not reflected in traditional methods for fitting covariance structures to sample covariance matrices. These approaches generally fit a covariance structure $\bm{\Omega}(\bm{\gamma})$ to a sample covariance matrix $\mathbf{S}$ by minimizing a discrepancy function $F(\mathbf{S}, \bm{\Omega}(\bm{\gamma}))$. For instance, a common choice of discrepancy function is the maximum likelihood discrepancy function,

\begin{equation}
F_{\textrm{ML}}(\mathbf{S}, \bm{\Omega}(\bm{\gamma})) = \ln |\bm{\Omega}(\bm{\gamma})| - \ln |\mathbf{S}| + \tr [\mathbf{S} \bm{\Omega}(\bm{\gamma})^{-1}] - p.
(\#eq:disc-ml-wb)
\end{equation}

\noindent Note that \autoref{eq:disc-ml-wb} is equivalent to \autoref{eq:disc-ml} with $\mathbf{S}$ substituted for $\bm{\Sigma}$. The discrepancy function is called "maximum likelihood" because minimizing the function is equivalent to maximizing the likelihood function for the Wishart distribution, $\textrm{W}_p(\bm{\Omega}(\bm{\gamma}) / n, n)$. This Wishart distribution is the sampling distribution of $\mathbf{S}$ under the assumption that $\bm{\Sigma} = \bm{\Omega}(\bm{\gamma})$ for some $\bm{\gamma} = \bm{\gamma}_0$, and the assumption of normality [@wu2015]. The asymptotic distribution of the maximum likelihood parameter estimate, $\hat{\bm{\gamma}}_{\textrm{ML}}$ can then be derived [e.g., @shapiro2007, Theorem 5.5, p. 249], and confidence intervals for parameters can be constructed [@joreskog1969].

Unfortunately, using maximum likelihood estimation requires assumptions that are unlikely to hold in many applied settings. First, the maximum likelihood discrepancy function is derived using normal distribution theory and can be sensitive to violations of normality [@browne1988]. However, maximum likelihood estimates can also be derived using a model that does not require any distributional assumptions [@howe1955; @mulaik2009foundations, pp. 214-215] and normal theory methods have been shown to be robust under certain circumstances [@browne1988]. A more troublesome issue highlighted by Wu and Browne [-@wu2015] is that using the maximum likelihood discrepancy function defined in \autoref{eq:disc-ml-wb} implicitly assumes that the theorized model holds perfectly in the population and that all differences between the sample and population covariance matrices are attributable to sampling error [@briggs2003; @wu2015]. Because adventitious error is not considered as a source of random variation, the variability estimates (and therefore confidence intervals) of parameter estimates and test statistics will be underestimated when using the traditional approach to model estimation [@wu2015].

Unlike the traditional approach, Wu and Browne's [-@wu2015] estimation method accounts for variability due to adventitious error by modeling adventitious error as a random effect with a distribution. The estimated dispersion parameter of this distribution can then be used as a measure of model misspecification. The statistical basis for their model is as follows. First, under the assumption of normality, the sample covariance matrix $\mathbf{S}$ has a Wishart distribution such that

\begin{equation}
(\mathbf{S} | \bm{\Sigma}) \sim \textrm{W}_p(\bm{\Sigma}/n, n),
(\#eq:S-dist)
\end{equation}

\noindent where $n$ is the degrees of freedom. As opposed to the traditional method where $\mathbf{S}$ is assumed to be an unbiased estimator of the model-implied population covariance matrix $\bm{\Omega}(\bm{\gamma})$, here $\mathbf{S}$ is instead assumed to be an unbiased estimator of the error-perturbed population covariance matrix, $\bm{\Sigma}$. $\bm{\Sigma}$ is then assumed to follow an inverse-Wishart distribution such that

\begin{equation}
(\bm{\Sigma} | \bm{\Omega}, m) \sim \textrm{W}^{-1}_p (m \bm{\Omega}, m),
(\#eq:Sigma-dist)
\end{equation}

\noindent where $m$ is a continuous precision parameter such that $m > p-1$ [@wu2015]. Wu and Browne [-@wu2015] also introduced the inverse of this precision parameter, $v = 1/m \in [0, (p-1)^{-1})$, which gives the dispersion of the adventitious error and can also be interpreted as a measure of misspecification. In particular, Wu and Brown [-@wu2015, p. 580] show that $v \approx \varepsilon^2$, where $\varepsilon$ denotes the RMSEA. Because $v$ has an upper bound of $1/(p-1)$, Wu and Browne suggested using $\sqrt{\tilde{v}} = (m - p + 1)^{-1/2}$ as the criterion of model admissibility. Specifically, they stated that $\sqrt{\tilde{v}} = 0.05$ is indicative of good model fit, values of $\sqrt{\tilde{v}}$ between 0.05 and 0.08 are indicative of acceptable model fit, and values above 0.08 are indicative of unacceptable model fit.

Wu and Browne's [-@wu2015] model therefore has two sets of parameters, $\bm{\gamma}$ and $v$, that require estimation. They showed that these parameters can be estimated by maximizing the likelihood function corresponding to the marginal distribution of the sample covariance matrix, $(\mathbf{S} | \bm{\Omega}, m)$, with the population covariance matrix $\bm{\Sigma}$ integrated out. Wu and Browne's choice of a conjugate distribution for $\bm{\Sigma}$ means that the marginal distribution of the sample covariance matrix follows a Type II matrix-variate beta distribution [@gupta2000, Chapter 5],

\begin{equation}
(\mathbf{S} | \bm{\Omega}, m) \sim \mathbf{B}^{\textrm{II}}_{p}\left(\frac{n}{2}, \frac{m}{2}, \frac{m}{n}\bm{\Omega} \right),
(\#eq:matrix-variate-beta)
\end{equation}

\noindent from which the probability density function and log-likelihood functions can be obtained [see @wu2015 for additional details]. The parameter estimate obtained by maximizing the beta marginal likelihood (or equivalently, minimizing the negative twice beta log-likelihood) is referred to as the maximum beta likelihood estimate (MBLE).

In addition to showing how to estimate $\bm{\gamma}$ and $v$, Wu and Browne [-@wu2015] derived sampling distributions and confidence intervals for $\hat{\bm{\gamma}}$ and $\hat{v}$. An important advantage of Wu and Browne's method over more traditional estimation methods is that their confidence intervals for $\hat{\bm{\gamma}}$ account for the amount of model error indicated by $\hat{v}$. They provided simulation evidence showing that confidence interval coverage rates for both estimated parameters were close to their nominal values, at least when $n$ and $m$ were relatively large and when $(\bm{\Sigma} | \bm{\Omega}, m) \sim \textrm{W}^{-1}_p (m \bm{\Omega}, m)$. Moreover, they also showed that coverage rates for 95% confidence intervals estimated using their method were much closer to the nominal levels compared to confidence intervals estimated using the traditional approach. Although these results were obtained from $\bSigma$ matrices simulated according to the process assumed by Wu and Browne's model, they claim that their method is robust regarding the distribution of model error when model error is small and that their method will reject the covariance structure when model error is not small [@wu2015a].

Thus far, this section has focused on Wu and Browne's [-@wu2015] method for estimating parameters and constructing confidence intervals for covariance structure models. However, as noted previously, Wu and Browne's model assumes that a covariance matrix with imperfect model fit is a random sample from an inverse-Wishart distribution, as shown in \autoref{eq:Sigma-dist}. Given a model-implied population covariance matrix $\bm{\Sigma}$ and some chosen value of the precision parameter $m$, covariance matrices with imperfect fit can be easily sampled from an appropriate inverse-Wishart distribution using statistical software such as R [@R-base], MATLAB [@matlab], or Julia [@bezanson2017julia]. The degree of model error (in terms of RMSEA) can be controlled to some extent by choosing an appropriate value of $m$, which Wu and Browne showed has a relationship with RMSEA such that $\sqrt{1/m} = \sqrt{v} \approx \varepsilon$ [@wu2015, Eq. 16, p. 580].

## Population Model Fit Indices {#population-model-fit}

In addition to being able to generate error-perturbed covariance matrices, it is important to be able to quantify the lack-of-fit between an error-perturbed population covariance matrix and a model-implied covariance matrix. Before describing the various model-fit indices that have been used to quantify model error, it will be helpful to first describe two different perspectives of model fit as it relates to model error. In the first, model error is quantified as the lack-of-fit between $\bm{\Sigma}$ and $\bm{\Omega}$. In the second, model error is quantified as the lack-of-fit between $\bm{\Sigma}$ and $\hat{\bm{\Omega}}$, the implied covariance matrix from fitting a particular model to $\bm{\Sigma}$. These two perspectives are equivalent in the special case when $\hat{\bm{\Omega}} = \bm{\Omega}$, which occurs when the CB method is used (because $\bm{\gamma}_0$ is required to be a minimizer of the chosen discrepancy function). For the purposes of this dissertation, I will focus primarily on the first model fit perspective. Unless specified, all model fit indices reflect the first perspective, indicating the lack-of-fit between between $\bm{\Sigma}$ and $\bm{\Omega}$. Where I discuss a model fit index indicating the lack-of-fit between $\bm{\Sigma}$ and $\bm{\Omega}$, a "$\bm{\Omega}$" subscript is used to make it clear that model fit is being considered from the first perspective. Where I discuss a model fit index indicating the lack-of-fit between $\bm{\Sigma}$ and $\hat{\bm{\Omega}}$, a "$\hat{\bm{\Omega}}$" subscript is used instead. I.e., I use $\rmseaOmega$ to indicate the root mean square error of approximation between $\bm{\Sigma}$ and $\bm{\Omega}$, and $\rmseaOmegaHat$ to indicate the root mean square error of approximation between $\bm{\Sigma}$ and $\hat{\bm{\Omega}}$.

As described in the previous section, the population RMSEA value is often used to describe the lack-of-fit between population covariance matrices due to model error. Other fit indices such as the Tucker-Lewis Index [TLI\; @tucker1973], the Comparative Fit Index [CFI\; @bentler1990], and the Standardized Root Mean Square Residual [SRMR\; @hu1999] have also be used for this purpose. Although far from an exhaustive list, these fit indices are among the most popular in the psychometric literature and can be divided into two general categories [@hu1999]. First, RMSEA and SRMR are absolute fit indices that report model fit in terms of the difference between a particular covariance matrix and a model-implied covariance matrix, without using a reference or baseline model for comparison. In the population context, absolute fit indices answer the question, "How different is $\bm{\Sigma}$ to $\bm{\Omega}$?" On the other hand, the TLI and CFI are incremental fit indices, which reflect the improvement of fit of a particular model compared to a (restricted, nested) baseline model. The null or independence model is often used as the baseline model, answering the question, "How well is my model doing, compared with the worst model that there is?" [@miles2007, p. 870]. 

RMSEA, CFI, TLI, and SRMR are generally defined in terms of the sample covariance matrix, but can be expressed in their population form (i.e., with reference to $\bm{\Sigma}$) as follows. Let $F_h$ and $F_b$ be the minimized discrepancy function values for the hypothesized and baseline models (respectively) at the population level. Furthermore, let $df_h$ and $df_b$ be the degrees of freedom for the hypothesized and baseline models. Then the population RMSEA value is given by

\begin{equation}
\RMSEA = \varepsilon = \sqrt{\frac{F_h}{df_h}},
(\#eq:rmsea)
\end{equation}

\noindent the population CFI value is given by

\begin{equation}
\textrm{CFI} = 1 - \frac{F_h}{F_b},
(\#eq:cfi)
\end{equation}

\noindent and the population TLI value is given by

\begin{equation} 
\textrm{TLI} = 1 - \frac{F_h / df_h}{F_b / df_b}.
(\#eq:tli)
\end{equation}

\noindent Note that for $\rmseaOmega$, $\cfiOmega$, and $\tliOmega$, $F_h$ is the minimized discrepancy function value when the discrepancy function is applied to $\bSigma$ and $\bOmega$ (i.e., the population covariance matrix with model error and the population covariance matrix implied by the major-factors model). For $\rmseaOmegaHat$, $\cfiOmegaHat$, and $\tliOmegaHat$, $F_h$ is the minimized discrepancy function value when the discrepancy function is applied to $\bSigma$ and $\bOmegaHat$ (the model-implied covariance matrix obtained by analyzing $\bSigma$).

Unlike RMSEA, CFI, and TLI, the population SRMR does not depend on discrepancy function values and is given by

\begin{equation}
\textrm{SRMR}_{\bOmega} = \sqrt{ \frac{1}{p (p + 1) / 2} \sum_{i \leq j} \left(  \frac{\sigma_{ij} - \omega_{ij}}{\sqrt{\sigma_{ii} \sigma_{jj}}} \ \right) ^2 },
(\#eq:srmr)
\end{equation}

\noindent where $p$ is the number of observed variables, and $\sigma_{ij}$ and $\omega_{ij}$ are the $i,j$th elements of $\bm{\Sigma}$ and $\bm{\Omega}$, respectively [@maydeu-olivares2017; @xia2019; @pavlov2021]. Note that when $\bm{\Sigma}$ and $\bm{\Omega}$ are constrained to be correlation matrices with unit diagonals, the correlation root mean residual [CRMR\; @bollen1989a; @ogasawara2001] is appropriate:

\begin{equation}
\crmrOmega = \sqrt{ \frac{1}{p (p - 1) / 2} \sum_{i < j} \left( \sigma_{ij} - \omega_{ij} \ \right) ^2 }.
(\#eq:crmr)
\end{equation}

\noindent Substituting the elements of $\bOmegaHat$ for the elements of $\bOmega$ in \autoref{eq:crmr} and \autoref{eq:srmr} give the equations for $\crmrOmegaHat$ and $\textrm{SRMR}_{\bOmegaHat}$.

Although all of the fit indices discussed here have been used to quantify model error in simulation studies [e.g., @lai2020b; @lai2020c; @lai2017; @xia2016a; @nguyen2022], the population RMSEA is perhaps the most widely-used. Indeed, many simulation studies using the TKL, CB, or WB model-error methods have grouped simulated covariance matrices into model fit categories based on highly-cited "rule-of-thumb" RMSEA cutoff values. For instance, Lorenzo-Seva and Ferrando [-@lorenzo-seva2020] used RMSEA values of 0.065 to represent models with fair fit, citing Browne and Cudeck [-@browne1992]. @myers2015a used RMSEA values of 0.025, 0.065, and 0.090 to categorize models as having very good fit, fair fit, and poor fit (respectively), citing Browne and Cudeck [-@browne1992], Steiger [-@steiger1989ezpath], and @jackson2009. According to Lai and Green [-@lai2016, p. 220]: 

> The most widely used cutoffs for RMSEA yield the following interpretations: (a) Values less than .05 (Browne & Cudeck, 1992) or .06 (Hu & Bentler, 1999) suggest 'good' fit; (b) values between .05 and .10 suggest 'acceptable' fit (Browne & Cudeck, 1992; MacCallum, Browne, and Sugawara, 1996); and (c) values larger than .10 suggest 'bad' fit (Browne & Cudeck, 1992).

\noindent However, rule-of-thumb cutoffs based on other common fit indices such as CFI can lead to conclusions about model fit that disagree with those indicated by RMSEA. 

The problem of disagreement among fit indices was explored in detail by Lai and Green [-@lai2016], who derived necessary and sufficient conditions for disagreement between CFI and RMSEA (when used with common cutoff values). For instance, Lai and Green (2016) showed that "good" RMSEA values and "bad" CFI values (i.e., RMSEA $\leq 0.05$ and CFI $\leq 0.90$) will occur when $df_h \leq 400 F_b \leq 10 df_h$, where $df_h$ denotes the model degrees of freedom and $F_b$ is the discrepancy function value for the baseline null (independence) model. Lai and Green [-@lai2016] also showed that $F_b = -\ln |\mathbf{S}|$ for an observed correlation matrix and that $\ln |\mathbf{S}|$ will be large (and $-\ln |\mathbf{S}|$ small) when the elements of $\mathbf{S}$ are close to zero. Thus, models will have "good" RMSEA but "bad" CFI when the elements of $\mathbf{S}$ are small (but large enough that $F_b > df_h / 400$) and when the model degrees of freedom value is large (but small enough that $df_h < 400 F_b$; Lai and Green, 2016). Lai and Green [-@lai2016] concluded that disagreement between CFI and RMSEA does not reflect a failure on the part of either fit index. Rather, disagreement occurs because the two fit indices evaluate model fit from different perspectives and the cutoffs used to make qualitative judgments about model fit are arbitrary. 

Unfortunately, disagreement between fit indices is a problem for researchers attempting to simulate covariance matrices with some particular qualitative level of model fit. Consider, for instance, a simulated covariance matrix with RMSEA = 0.04 and CFI = 0.78.[^model-fit-example] An RMSEA value of 0.04 indicates good model fit based on most rule-of-thumb cutoff values [@browne1992]. However, CFI values less than 0.90 are seldom considered to indicate acceptable fit [@lai2016]. How should this covariance matrix (and others like it) be categorized in a simulation study? No straightforward answer is apparent. The essential problem, as stated by @kline2011, is that "*there is no such thing as a magical, single-number summary that says everything worth knowing about model fit*" (p. 193). Therefore, a common recommendation is to report multiple fit indices to get a more complete picture of model fit [@kline2011; @lai2016]

[^model-fit-example]: This is not just a hypothetical example. Simulated correlation matrices leading to similar RMSEA and CFI values were encountered in simulations conducted by Kracht and Waller (2020).

Despite the recommendation to report multiple fit indices, only a handful of simulation studies that incorporate error-perturbed covariance matrices report fit indices other than RMSEA [@kracht2022; @lai2020b; @lai2020; @lai2019a; @lai2018; @lai2017; @lai2016]. The reliance on a single model fit index (usually RMSEA) when generating error-perturbed covariance matrices can be explained by the characteristics of the TKL, CB, and WB model-error methods. 

In the case of the TKL method, little is known about which values of the TKL parameters ($\epsilon$ and $\nu_\textrm{e}$) are reasonable for generating data that are representative of empirical data. Without clear guidance about which parameter values to use, researchers using the TKL method in simulation studies have often relied on RMSEA values to determine whether resulting correlation matrices were representative of empirical data sets. For instance, Briggs and MacCallum [-@briggs2003] used the TKL method to generate data sets they categorized as having either good or moderate model fit. In their simulation study, error-perturbed covariance matrices were retained or rejected based on their RMSEA values. A matrix was retained if the RMSEA resulting from a maximum likelihood factor analysis fell within the range .030--.049 for the good fit condition and within the range .070--.089 for the moderate model fit condition. 

Other researchers have also used RMSEA as a measure of model misfit when using the TKL method in Monte Carlo simulation studies [@lorenzo-seva2020; @kracht2022; @gnambs2016; @myers2015a; @preacher2013; @preacher2002; @nguyen2022]. One difficulty with this approach is that it can be challenging to choose values of $\epsilon$ and $\nu_\textrm{e}$ that lead to desired RMSEA values while varying factor model characteristics (e.g., number of factors, factor salience, factor correlations, etc.). Manually choosing parameters that routinely lead to desired RMSEA values and desired values of another fit statistic (such as CFI) is even more challenging. Thus, researchers who use the TKL method in simulation studies generally select the values of $\epsilon$ and $\nu_\textrm{e}$ based on only RMSEA.

Researchers who choose to instead generate error-perturbed covariance matrices using the CB method often use RMSEA as a measure of model misfit because the CB method allows them to specify a desired discrepancy function value (and therefore a desired RMSEA value). However, the CB method has no other user-specified parameters than can be changed to influence model fit indices that measure other aspects of model fit (such as CFI). Lai and Green [-@lai2016] used the CB method to generate covariance matrices with specified RMSEA and CFI values, but did so by updating the factor loadings and uniqueness variances in the population model while holding RMSEA constant. Although this approach is effective, it has the significant drawback of not allowing researchers to systematically vary model parameters across experimental conditions. 

Similar to the CB method, the WB method allows the user to choose a desired RMSEA value but does not provide an easy way to specify a desired a CFI value (or any alternative fit index). The WB method is also less precise than the CB method in the sense that it only allows the user to specify a distribution for the model-perturbed covariance matrices and thus does not guarantee that the RMSEA value for a simulated covariance matrix will be very close to the target value.