
# A Method for Generating Error-Perturbed Covariance Matrices with Specified Levels of Model Fit

Given that model fit cannot be fully described by a single fit index, it is desirable to have a model fit method that would allow for the simultaneous specification of multiple fit indices (e.g., RMSEA and CFI). To date, RMSEA has been used almost exclusively to quantify the amount of model error introduced by a model-error method, and is the only fit index that can be specified in advance when using the CB and WB methods [@briggs2003; @cudeck1992; @wu2015]. 

In this section, I propose a procedure based on the TKL method that uses optimization to find parameter values that lead to error-perturbed covariance matrices with RMSEA and CFI values that are close to user-specified target values. RMSEA and CFI are used because they are among the most commonly-used model fit indices and reflect different aspects of model fit [absolute and incremental model fit\; @kline2011]. However, in theory the procedure could be extended to work with any two fit indices.[^more-than-two] The proposed procedure also allows the user to impose constraints on the number of large minor factor loadings to ensure a clear delineation between major and minor factors in the TKL framework. Because the optimization procedure allows for RMSEA and CFI targets and constraints on factor loadings, I will refer to it as the "multiple-target optimization method" or "the multiple-target method".

[^more-than-two]: In fact, the procedure could easily be extended to include three or more fit indices. However, the marginal benefit of including additional fit indices is unlikely to be large and could make optimization more difficult.

The proposed procedure uses the limited memory Broyden-Fletcher-Goldfarb-Shanno optimization algorithm with box constraints [L-BFGS-B\; @byrd1995] to minimize the objective function

\begin{equation}
G(\nu_\textrm{e}, \epsilon) = b_1 \frac{\left[ \varepsilon - \varepsilon_T \right]^2}{\varepsilon_T^2} + b_2 \frac{\left[ \textrm{CFI} - \textrm{CFI}_T \right]^2}{\left( 1 - \textrm{CFI}_T \right)^2} + 1_{\mathbf{W}} \lambda,
(\#eq:rmsea-cfi-obj-function)
\end{equation}

\noindent where $0 \leq \nu_\textrm{e} \leq 1$, $0 \leq \epsilon \leq 1$, $b_1$ and $b_2$ are user-specified weights constrained to sum to one. Setting $b_1 = b_2 = 0.5$ places equal weight on RMSEA and CFI, whereas unequal weights can be used to indicate a preference for one fit index over the other. If either weight is set to zero, the corresponding fit index has no effect on optimization. Thus, the optimization procedure seeks to find values of $\nu_\textrm{e}$ and $\epsilon$ such that the weighted sum of the mean squared error between the observed and target RMSEA and the mean squared error between the observed and target CFI is minimized.

The right-most term in \autoref{eq:rmsea-cfi-obj-function} consists of a user-defined penalty, $\lambda$, and an indicator function, $1_{\mathbf{W}}$. The indicator function $1_{\mathbf{W}}$ is equal to one whenever a user-specified number of (absolute) minor factor loadings are greater than some threshold value for any minor factor, and zero otherwise. The addition of this penalty term attempts to ensure a clear delineation between major and minor factors. For instance, a user could specify that no more than two minor factor loadings should be greater than 0.3 in absolute value. If the penalty term is set to some large value (e.g., $\lambda = 100$), TKL parameters that lead to models with too many large minor factor loadings will be heavily penalized. 

Empirical testing of the multiple-target method showed that some combinations of target fit index values and constraints on the $\mathbf{W}$ matrix sometimes led to non-convergence when using the L-BFGS-B algorithm. In particular, non-convergence was observed when using relatively high target RMSEA values and relatively low target CFI values, and when there were only a small number of factors. Non-convergence can often be remedied by restarting optimization with different starting parameter values. If non-convergence still occurs after trying multiple different starting values, global optimization using a genetic algorithm [GA\; @holland1975] can be used to minimize the objective function in \autoref{eq:rmsea-cfi-obj-function}. 

GAs take inspiration from biological evolutionary processes and natural selection to find candidate solutions that have a high level of fitness (i.e., that lead to high/low objective function values during maximization/minimization). Many variations of GAs have been proposed [@scrucca2013], but the procedure for most GAs can be generally described as follows. First, a random set of candidate solutions is generated and the fitness (i.e., objective function value) for each solution is evaluated. Next, a pair of "parent" solutions are selected (with replacement) from the set such that solutions with higher fitness have a higher selection probability. The parent solutions then produce two offspring with user-defined crossover and mutation probabilities. If crossover occurs, the children are formed as combinations of their parents using some crossover function. If crossover does not occur, the children are formed as exact copies of their parents. Similarly, if mutation occurs, the child solution is randomly perturbed. This process continues until there are as many children in the new generation as there were parents in the previous generation. Once the new generation is formed, selection occurs again and the process continues until a fixed number of generations have passed or until some stopping criterion is reached [@mitchell1996; @scrucca2013].

Although GAs work well for many problems where derivative-based methods have difficulty [e.g., when the objective function is not smooth or when there are local optima\; @scrucca2013], a downside is that they can be relatively slow compared to derivative-based optimization methods when applied to more "well-behaved" optimization problems. Therefore, the proposed optimization procedure first attempts to use the L-BFGS-B method to find a solution (with multiple random starts if convergence does not occur). If convergence still does not occur after multiple random starts using L-BFGS-B, a GA is used to find a solution. The advantage of this approach is that the procedure quickly produces a solution when the user-specified values make the problem well-suited for derivative-based optimization. If the derivative-based optimization fails, the procedure can still find a solution using the GA, albeit somewhat more slowly.

It is important to note that the multiple-target method will not necessarily produce solutions with RMSEA and CFI values that are exactly equal to the target values. For some models, it can be difficult---potentially impossible---to obtain particular combinations of RMSEA and CFI values (e.g., when modeling correlation matrices with many items, a low $\epsilon_T$ value and a high $\textrm{CFI}_T$ value). Moreover, the method is not guaranteed to find solutions that are global minima. Thus, users should check solutions to make sure that the model fit values are sufficiently close to the target values for their purposes. These issues will be investigated more thoroughly in the simulation study that is described in the next section.
