
# Discussion {#discussion}

In this dissertation, I conducted a large-scale simulation study to compare several methods for simulating population correlation matrices with model error. The model-error methods I compared were the Cudeck and Browne [CB\; @cudeck1992] method, the Wu and Browne [WB\; @wu2015] method, and three variations of the Tucker, Koopman, and Linn [TKL\; @tucker1969] model-error method using a novel optimization procedure to automatically select values of the TKL method parameters, $\epsilon$ and $\nu_{\textrm{e}}$. The addition of the optimization procedure allowed the use of the TKL method with specified target values of RMSEA (the $\textrm{TKL}_{\textrm{RMSEA}}$ variation), CFI (the $\textrm{TKL}_{\textrm{CFI}}$ variation), or both fit indices simultaneously (the $\textrm{TKL}_{\textrm{RMSEA/CFI}}$ variation). Moreover, the optimization procedure also allowed users to impose constraints on the loadings of the minor common factors introduced by the TKL method to ensure that there was a clear delineation between major and minor common factors. To facilitate the use of all of the model-error methods discussed in this dissertation, I also developed an R package (*noisemaker*) that serves as an easy-to-use, unified interface for simulating correlation matrices with model error.

Through the simulation study I conducted, I hoped to answer two primary questions about the model-error methods I investigated. First, I wanted to know whether the five model-error methods included in the study (the $\textrm{TKL}_{\textrm{RMSEA}}$, $\textrm{TKL}_{\textrm{CFI}}$, $\textrm{TKL}_{\textrm{RMSEA/CFI}}$, CB, and WB methods) led to different values of the CFI, TLI, and CRMR fit indices when used with the same error-free population correlation matrices and target RMSEA values. If all of the model-error methods led to the same (or similar) fit index values, it would have suggested that the choice of which model-error method to use is not very important when conducting simulation studies involving covariance structure models. The second question I wanted to answer was how effective the modified TKL method with the proposed optimization procedure (referred to as the multiple-target TKL method) worked. That is, I was interested in determining how well the multiple-target TKL method was able to generate correlation matrices with model error that had RMSEA and CFI values that were close to the specified values. Note that in the following discussion of the simulation results I focus on the RMSEA and CFI fit indices for two reasons. First, RMSEA and CFI target values were used in the simulation study and are often used as indications of model fit when generating population correlation matrices with model error [@tucker1969; @cudeck1992; @kracht2022; @trichtinger2020]. Second, the CRMR and TLI indices led to results that were similar to the results for RMSEA and CFI, respectively.

Concerning the first primary research question, the results of my simulation study indicated that there were important differences between the five model-error methods in terms of the observed model fit indices they led to. Although all of the model-error methods led to similar RMSEA, CFI, TLI, and CRMR values in conditions with few major factors, strong factor loadings, and good model fit, they led to much more disparate results in other conditions. In particular, the results of the simulation study indicated that there were important differences between model-error methods that (a) incorporated only a target RMSEA value (i.e., the $\textrm{TKL}_{\textrm{RMSEA}}$, CB, and WB methods), (b) incorporated only a target CFI value (the $\textrm{TKL}_{\textrm{CFI}}$ method), or (c) incorporated both RMSEA and CFI target values (the $\textrm{TKL}_{\textrm{RMSEA/CFI}}$ method). 

When evaluated on RMSEA, the model-error methods that only incorporated target RMSEA values generally produced solutions with observed RMSEA values very close to the target values. In particular, the $\textrm{TKL}_{\textrm{RMSEA}}$ and CB methods led to RMSEA values that almost always extremely close to the target values, whereas there was slightly more variability in the RMSEA values from the WB method. On the other hand, the model-error methods that incorporated CFI target values often led to RMSEA values that were lower than the target values, particularly in conditions with many major common factors and weak factor loadings. The result that the $\textrm{TKL}_{\textrm{RMSEA}}$, CB, and WB model-error methods led to solutions with RMSEA values that were close to the target values is perhaps unsurprising, given that this was what all three methods were designed to do. However, it confirms that the CB method worked as expected and provides evidence that the  modifications of the TKL and WB methods to incorporate target RMSEA values were successful. On the other hand, the $\TKLrmsea$ and $\TKLrmseacfi$ methods both led to solutions with RMSEA values that were further from the target RMSEA values in most conditions, particularly when model fit was Poor or when there were many major common factors.

When evaluated on CFI, the two model-error methods that incorporated target CFI values ($\textrm{TKL}_{\textrm{CFI}}$ and $\textrm{TKL}_{\textrm{RMSEA/CFI}}$) generally produced observed CFI values that were closer to the target values than the other model error methods. Although all of the model-error methods led to observed CFI values that were close the target values in conditions with strong factor loadings and Very Good model fit, the $\textrm{TKL}_{\textrm{RMSEA}}$, CB, and WB methods often led to unacceptably low CFI values in other conditions. Interestingly, the $\TKLcfi$ and $\TKLrmseacfi$ methods often led to quite similar results, despite the $\TKLrmseacfi$ method incorporating a target RMSEA value. This seemed to be because CFI was often more sensitive to changes in parameter values compared to RMSEA, particularly in conditions with many factors, many items per factor, and low factor loadings. A small change in parameter values that produced an RMSEA value slightly closer to the target value often resulted in a large change in CFI away from the target value. Correspondingly, small changes in parameter values that produced a CFI value closer to the target value generally had only a small effect on the RMSEA value. As a result, the $\TKLrmseacfi$ method tended to "prioritize" target CFI values, despite both RMSEA and CFI being weighted equally in the objective function.

The result that the $\textrm{TKL}_{\textrm{CFI}}$ and $\textrm{TKL}_{\textrm{RMSEA/CFI}}$ methods led to RMSEA values that were often far from the target suggested a problem with using only target RMSEA values to generate correlation matrices with model error. Namely, the problem was that solutions with RMSEA values that were close to target RMSEA values often had CFI values that indicated a worse qualitative level of model fit. For instance, in conditions with five factors, weak factor loadings, and Very Good (target) model fit, the $\textrm{TKL}_{\textrm{RMSEA}}$ method produced solutions with RMSEA values that were very close to the target RMSEA value of .025. However, none of corresponding CFI values for those solutions reached the target value of .99 (considered to represent Very Good model fit), and many CFI values were below .90 (a liberal threshold for acceptable model fit). These results indicate that using RMSEA alone to adjudicate model fit makes it not only possible, but *likely* that simulated population correlation matrices would be included in conditions with nominally excellent model fit as indicated by RMSEA values, but with unacceptably poor model fit as indicated by CFI values. These results agreed with results reported by Kracht and Waller [-@kracht2022], who used the TKL method with manually-selected parameter values to produce matrices with RMSEA values in a particular range. They found that although they were able to select parameter values that led to solutions with RMSEA values in the desired ranges, the CFI values for those solutions were often below the standard cutoff values. Furthermore, they reported that CFI values were lowest in conditions with many items, low factor loadings, and poor model fit.

The fact that all of the model error method often produced solutions with RMSEA and CFI values indicating different levels of qualitative model fit presents a problem for researchers who would like to generate population correlation matrices with fit indices indicating a particular degree of model fit. Choosing to use the $\textrm{TKL}_{\textrm{RMSEA}}$, CB, or WB methods would likely lead to correlation matrices with the desired RMSEA values for most conditions, but unacceptably low CFI values. On the other hand, choosing to use the $\textrm{TKL}_{\textrm{CFI}}$ or $\textrm{TKL}_{\textrm{RMSEA/CFI}}$ would lead to almost the complete opposite problem; solutions would be likely to have observed CFI values near the target values, but would also be likely to have smaller-than-desired RMSEA values. To determine which of the model-error methods led to the highest rates of fit index agreement, I evaluated fit index agreement in two ways. First, I evaluated each model error method in terms of the sum of the absolute differences between the observed and target RMSEA and CFI values, defined as $D$ in \autoref{eq:distance-between-observed-and-target}. When evaluated on this criterion, the $\textrm{TKL}_{\textrm{CFI}}$ and $\textrm{TKL}_{\textrm{RMSEA/CFI}}$ methods led to much better results than the other investigated model-error methods, having the lowest median $D$ values over all conditions. Moreover, the $\textrm{TKL}_{\textrm{CFI}}$ and $\textrm{TKL}_{\textrm{RMSEA/CFI}}$ methods often led to much lower $D$ values than the alternatives (particularly in conditions with many factors, weak factor loadings, and Poor model fit) and rarely led to higher $D$ values.

The second way I evaluated fit-index agreement was by using rule-of-thumb RMSEA and CFI threshold values to categorize correlation matrices as having good, acceptable, or unacceptable model fit and then determining how often RMSEA and CFI values led to the same level of qualitative model fit for each model-error method. The results of the simulation study indicated that the $\textrm{TKL}_{\textrm{RMSEA/CFI}}$ method was by far the most likely model-error method to produce solutions with qualitative model fit agreement, followed by the CB, $\textrm{TKL}_{\textrm{CFI}}$, $\textrm{TKL}_{\textrm{RMSEA}}$, and WB methods. These results suggest that the $\TKLcfi$ model is the best choice (of the model-error methods considered here) for researchers who would like to generate correlation matrices with model error and who would like to ensure that the matrices they generate have RMSEA and CFI values that indicate the same level of qualitative model fit. However, it is also important to note that in many conditions (e.g., in conditions with many factors, Weak factor loadings, and Poor model fit), all of the model-error methods had qualitative fit agreement rates close to zero.

The result that the $\TKLcfi$ method led to both the smallest average $D$ values and the highest rate of qualitative fit agreement (using RMSEA and CFI) was quite surprising. Before conducting the simulation study, I predicted that the $\TKLrmseacfi$ method would lead to both the smallest $D$ values and the highest rates of qualitative fit agreement because it incorporated both target RMSEA and CFI values. However, the simulation study results indicated that CFI values tended to change more quickly as a function of RMSEA values than *vice versa*, particularly for conditions with many factors, many items per factor, and strong factor loadings. Put another way, changing the TKL parameter values to produced a solution with an RMSEA value incrementally closer to the target value often resulted in a large change to the CFI value. This provided a plausible explanation for why the $\TKLrmseacfi$ and $\TKLcfi$ methods often led to similar results. Namely, because CFI values were more sensitive to changes to the TKL parameters than RMSEA, the $\TKLrmseacfi$ solutions were primarily influenced by the CFI targets (and thus often produced results similar to the $\TKLcfi$ method) despite the CFI and RMSEA targets being weighted equally in the objective function. 

Based on the results of the simulation study, I recommend that researchers who want to generate population correlation matrices with a particular level of model fit (as indicated by RMSEA and CFI values) should use the $\TKLcfi$ model-error method. I also recommend the $\TKLrmseacfi$ method as an acceptable alternative. This method produced lower rates of qualitative fit agreement compared to the $\TKLcfi$ method, but very similar results in terms of $D$. Although the $\TKLcfi$ method led to the smallest $D$ values for the particular combinations of RMSEA and CFI target values included in this study, it is possible that the $\TKLrmseacfi$ method might lead to smaller $D$ values when different combinations of target RMSEA and CFI values are used. I recommend that researchers experiment with both options before committing to use either in a particular study. 

Although the CB method led to the second-highest rate of qualitative model fit agreement, it also often led to substantially higher $D$ values compared to the $\TKLcfi$ and $\TKLrmseacfi$ model-error methods. Moreover, it had several drawbacks that keep me from recommending it for use in simulation studies. First, the CB method was prohibitively slow whenever $\bOmega$ was large (i.e., whenever there were many factors or items per factor).  Using the CB method with 150-variable conditions was so time-consuming that I had to drop them from my simulation design. The fact that the CB method is time consuming when $\bOmega$ is made all the more problematic because the CB method often produced indefinite $\bSigma$ matrices in those conditions. As noted in \@ref(indefinite-matrices), indefinite $\bSigma$ matrices are unacceptable candidates for population correlation matrices with model error because all correlation and covariance matrices are at least positive semi-definite by definition [@wothke1993; @lorenzo-seva2020a; @kracht2022]. Researchers hoping to obtain positive semi-definite $\bSigma$ matrices using the CB method with large $\bOmega$ matrices could simply generate a large number of solutions, rejecting indefinite $\bSigma$ matrices. However, given the completion time of the CB method and the high rates of indefinite solutions reported for many conditions of the simulation study, this is unlikely to be a feasible approach. Finally, it is unclear whether all of the desiderata of the CB method are, in fact, desirable. Specifically, it is not self-evident that the vector of population parameters should be perfectly recovered when the model is applied to $\bSigma$ using maximum likelihood (as it is in the CB method). Certainly, this constraint is not enforced by any of the alternative model-error methods. Even if a researcher finds the constraint reasonable and chooses to use the CB method as a result, the simulation results showed that the CB method often failed to find a solution such that $\bOmegaHat = \bOmega$ in some conditions.

Most of the issues associated with the CB method did not affect the $\TKLrmsea$ or WB model-error methods. For instance, neither method produced indefinite $\bSigma$ matrices and both methods had much shorter completion times compared with the CB method. However, I do not recommend either model error method for general use in simulation studies. Both the $\TKLrmsea$ and CB methods led to relatively high $D$ values and relatively low rates of qualitative model fit agreement. Additionally, the $\TKLrmsea$ method often led to solutions with strong minor factors that would more appropriately be considered major factors. Even the inclusion of a large penalty term ($\lambda$) did not prevent the $\TKLrmsea$ method from producing solutions that violated the constraint that no minor factor should have more than two absolute loadings greater than 0.3. On the other hand, the $\TKLcfi$ or $\TKLrmseacfi$ methods almost never  led to solutions that violated the minor factor constraints. In fact, the results of small-scale follow-up study indicated that the $\TKLcfi$ and $\TKLrmseacfi$ methods did not produce solutions that violated the minor factor constraints even when $\lambda = 0$ (i.e., when no penalty was applied). The simulation study results indicated that the inclusion of a reasonable target CFI value was almost always sufficient to avoid generating solutions with strong minor factors. One approach to dealing with solutions that violated the minor factor constraints would be to simply discard those solutions and continue generating new solutions until a sufficient number of solutions that did not violate the constraints were found. However, the study results indicated the $\TKLrmsea$ method almost always led to solutions that violated the minor factor constraints in conditions with many factors, many items per factor, and Poor model fit. Therefore, the strategy of discarding solutions that violated the minor factor constraints is likely to be highly inefficient (if not completely impractical) for those conditions.

## Limitations

As with any study, I acknowledge that the simulation study reported in this dissertation was subject to certain limitations. For instance, I designed the study to include a wide range of models that might plausibly be encountered in psychological research. However, there were still many types of models that were not included in the study design. 

<!---
[] I recommend using the $\TKLcfi$ method because it led to the best agreement rates. However, using the $\TKLrmseacfi$ method should lead to very similar results.
[] Using the $\TKLcfi$ or $\TKLrmseacfi$ methods has at least three other advantages as well compared to the alternative model-error methods:
  [] Both methods led to solutions without any major minor factors, despite the failure of the objective function penalty. On the other hand, the $\TKLrmsea$ method often led to solutions with major minor factors in some conditions. Although it is not possible to explicitly check for major minor factors with the CB and WB methods, neither method is able to avoid the problem. In conditions where the $\TKLrmsea$ method is likely to produce solutions with major minor factors, the CB method tended to produce solutions that were indefinite. Moreover, neither the CB or WB method provides any mechanism to avoid producing solutions that are better conceptualized as having more than the specified number of major common factors.
  
[] Finally, I demonstrated that the $\TKLrmseacfi$ method was able to generate solutions with RMSEA and CFI values that were extremely close to the specified target RMSEA values ...

[] Limitations:
  [] None of the model error methods were able to generate solutions with some combinations of RMSEA and CFI values. Further work should be done to determine whether certain combination of RMSEA and CFI are, in fact, impossible for a particular $\bOmega$ value.
  [] When I designed the optimization procedure for the TKL methods, I assumed that researchers would not have any a priori beliefs about plausible ranges of $\epsilon$ and $\nu_e$. However, a committee member suggested that researchers might consider certain parameter values implausible in practice. For instance, for an orthogonal model with all salient major factor loadings fixed at 0.8, a $\nu_e$ value of .90 would indicate that 94.4% of the variance for each item was reliable, which is highly-implausible in most contexts. To allow for researchers to include their a priori beliefs about plausible ranges of $\nu_e$ and $\eps$, the L-BFGS-B box-constraints in the TKL optimization procedure could be specified by a user. This change would allow users to specify upper and lower bounds on either $\epsilon$ or $nu_e$, or both simultaneously. The implementations of the TKL methods in the `noisemaker` package have been updated to enable this functionality.
  [] It might also be the case that researchers are more interested in producing solutions with RMSEA and CFI values that fall within a particular range, rather than finding RMSEA and CFI values that are as close as possible to the provided target values. Future work should be done to develop and implement an appropriate objective function that will penalize solutions with RMSEA and CFI values that fall outside of provided ranges. [Need to think about whether this makes sense or not.]
  [] 
--->


<!---
Find a way to work in: all methods led to similar results (in terms of RMSEA, CFI, CRMR, and TLI) in conditions with few factors, strong factor loadings, and very good model fit. However, the methods led to very different results in conditons with many major factors, relatively weak factor loadings, and poor model fit.

1. Model-error methods led to different outcomes in terms of RMSEA and CFI values.
  a. RMSEA
    i. The model-error methods that only used RMSEA targets led to (unsurprisingly) similar results in terms of RMSEA. In particular, the TKL_RMSEA, and CB methods both produced solutions with RMSEA values that were very close to the target RMSEA values. The distributions of observed RMSEA values for the solutions produced by the WB method were centered around the target RMSEA value, but were more variable than the RMSEA distributions for the TKL_RMSEA and CB methods.
    ii. On the other hand, the TKL_CFI, and TKL_RMSEA_CFI methods typically led to observed RMSEA values that were not as close to the target RMSEA values. In many cases, TKL_CFI, and TKL_RMSEA_CFI led to RMSEA values that were somewhat lower than the target values, particularly in conditions with many factors. 
  b. CFI
    i. When evaluated on CFI, the model-error methods again fell into groups according to whether or not they incorporated a CFI target value. 
    ...
    
2. When assessing which of these methods to use in simulation work, there are other considerations. (A) Completion time; (B) Non-convergence; (C) Indefinite Matrices.

Future Research:

1. More flexible targets; target fit index ranges rather than fit index values.
2. Marsh et al. in search of golden rules: use more varied (realistic) model error methods to establish rule-of-thumb cutoff values.
3. The proposed model-error methods will give researchers the ability to generate more realistic population models with model error and user-specified fit index values. This could help us better understand how fit indices 
4. User-specified bounds of v and epsilon for noisemaker.
5. What do my results say about which model-error method should be preferred?
--->

