
# Discussion {#discussion}

In this dissertation, I conducted a large-scale simulation study to compare several methods for simulating population correlation matrices with model error. The model-error methods I compared were the Cudeck and Browne [CB\; -@cudeck1992] method, the Wu and Browne [WB\; -@wu2015] method, and three variations of the Tucker, Koopman, and Linn [TKL\; -@tucker1969] model-error method using a novel optimization procedure to automatically select values of the TKL method parameters ($\epsilon$ and $\nu_{\textrm{e}}$). The addition of the optimization procedure allowed the TKL method to be used with specified target values of $\rmseaOmega$ (the $\textrm{TKL}_{\textrm{RMSEA}}$ variation), $\cfiOmega$ (the $\textrm{TKL}_{\textrm{CFI}}$ variation), or both fit indices simultaneously (the $\textrm{TKL}_{\textrm{RMSEA/CFI}}$ variation). Moreover, the optimization procedure also allowed users to impose constraints on the loadings of the minor common factors introduced by the TKL method to ensure that there was a clear delineation between major and minor common factors. To facilitate the use of all of the model-error methods discussed in this dissertation, I also developed an R package (*noisemaker*) that provides an easy-to-use, unified interface for simulating correlation matrices with model error.

Through this simulation study, I hoped to answer two primary questions about the model-error methods I investigated. First, were the model-error methods more or less exchangeable (in terms of the investigated model fit indices they led to) in each of the study conditions? If the model-error methods led to the same (or similar) fit index values, it would suggest that researchers should choose the model-error method they consider most similar to the data-generating model underlying real data. The second question I wanted to answer concerned the efficacy of the modified TKL method with the proposed optimization procedure (referred to as the multiple-target TKL method). That is, I was interested in determining how well the multiple-target TKL method was able to generate correlation matrices that had $\rmseaOmega$ and $\cfiOmega$ values that were close to the specified target values. Note that in the following discussion of the simulation results, I focus on the $\rmseaOmega$ and $\cfiOmega$ fit indices for three reasons. First, $\rmseaOmega$ and $\cfiOmega$ were used as target fit indices in the simulation study. Second, RMSEA and CFI are the most frequently-used fit indices in simulation studies involving model error [@tucker1969; @cudeck1992; @kracht2022; @trichtinger2020]. Third, the $\crmrOmega$ and $\tliOmega$ indices led to results that were similar to the results for $\rmseaOmega$ and $\cfiOmega$, respectively.

Concerning the first research question, the results indicated that there were important differences between the five model-error methods in terms of the observed model fit indices. Although all of the model-error methods led to similar $\rmseaOmega$, $\cfiOmega$, $\tliOmega$, and $\crmrOmega$ values in conditions with few major factors, strong factor loadings, and good model fit, they led to much more disparate results in other conditions. In particular, the results of the simulation study indicated that there were important differences between model-error methods that incorporated only a target $\rmseaOmega$ value (i.e., the $\textrm{TKL}_{\textrm{RMSEA}}$, CB, and WB methods) and methods that incorporated a target $\cfiOmega$ value (the $\textrm{TKL}_{\textrm{CFI}}$ and $\textrm{TKL}_{\textrm{RMSEA/CFI}}$ methods). 

When evaluated on $\rmseaOmega$, the model-error methods that only incorporated target $\rmseaOmega$ values generally produced solutions with observed $\rmseaOmega$ values very close to the target values. In particular, the $\textrm{TKL}_{\textrm{RMSEA}}$ and CB methods led to $\rmseaOmega$ values that were almost always extremely close to the target values, whereas there was slightly more variability in the $\rmseaOmega$ values from the WB method. On the other hand, the model-error methods that incorporated $\cfiOmega$ target values often led to $\rmseaOmega$ values that were lower than the target values, particularly in conditions with many major common factors and weak factor loadings. The result that the $\textrm{TKL}_{\textrm{RMSEA}}$, CB, and WB model-error methods led to solutions with $\rmseaOmega$ values that were close to the target values is perhaps unsurprising, given that this was what all three methods were designed to do. However, it confirms that the CB method worked as expected and provides evidence that the modifications of the TKL and WB methods to incorporate target $\rmseaOmega$ values were successful. On the other hand, the $\TKLrmsea$ and $\TKLrmseacfi$ methods both led to solutions with $\rmseaOmega$ values that were further from the target $\rmseaOmega$ values in most conditions, particularly when model fit was Poor or when there were many major common factors.

When evaluated on $\cfiOmega$, the two model-error methods that incorporated target $\cfiOmega$ values ($\textrm{TKL}_{\textrm{CFI}}$ and $\textrm{TKL}_{\textrm{RMSEA/CFI}}$) generally produced observed $\cfiOmega$ values that were closer to the target values than the other model error methods. Although all of the model-error methods led to observed $\cfiOmega$ values that were close to the target values in conditions with strong factor loadings and Very Good model fit, the $\textrm{TKL}_{\textrm{RMSEA}}$, CB, and WB methods often led to unacceptably low $\cfiOmega$ values in other conditions. Interestingly, the $\TKLcfi$ and $\TKLrmseacfi$ methods often led to quite similar results, despite the $\TKLrmseacfi$ method incorporating a target $\rmseaOmega$ value. This seemed to be because $\cfiOmega$ was more sensitive to changes in parameter values compared to $\rmseaOmega$, particularly in conditions with many factors, many items per factor, and low factor loadings. A small change in parameter values that produced an $\rmseaOmega$ value slightly closer to the target value often resulted in a large change in $\cfiOmega$ away from the target value. Correspondingly, small changes in parameter values that produced a $\cfiOmega$ value closer to the target value generally had only a small effect on the $\rmseaOmega$ value. As a result, the $\TKLrmseacfi$ method tended to "prioritize" target $\cfiOmega$ values, despite both $\rmseaOmega$ and $\cfiOmega$ being weighted equally in the objective function.

The result that the $\textrm{TKL}_{\textrm{CFI}}$ and $\textrm{TKL}_{\textrm{RMSEA/CFI}}$ methods led to $\rmseaOmega$ values that were often far from the target suggested a problem with using only target $\rmseaOmega$ values to generate correlation matrices with model error. Namely, the problem was that solutions with $\rmseaOmega$ values that were close to target $\rmseaOmega$ values often had $\cfiOmega$ values that indicated a worse qualitative level of model fit. For instance, in conditions with five factors, weak factor loadings, and Very Good (target) model fit, the $\textrm{TKL}_{\textrm{RMSEA}}$ method produced solutions with $\rmseaOmega$ values that were very close to the target $\rmseaOmega$ value of 0.025. However, none of the corresponding $\cfiOmega$ values for those solutions reached the target value of .99 (considered to represent Very Good model fit), and many $\cfiOmega$ values were below .90 (a liberal threshold for acceptable model fit). These results indicate that using $\rmseaOmega$ alone to adjudicate model fit makes it not only possible, but *likely* that simulated population correlation matrices would be included in conditions with nominally excellent model fit as indicated by $\rmseaOmega$ values, but with unacceptably poor model fit as indicated by $\cfiOmega$ values. These results agreed with results reported by Kracht and Waller [-@kracht2022], who used the TKL method with manually-selected parameter values to produce matrices with $\rmseaOmega$ values in a particular range. They found that although they were able to select parameter values that led to solutions with $\rmseaOmega$ values in the desired ranges, the $\cfiOmega$ values for those solutions were often below the standard cutoff values. Furthermore, they reported that $\cfiOmega$ values were lowest in conditions with many items, low factor loadings, and poor model fit.

The fact that all of the model error methods often produced solutions with $\rmseaOmega$ and $\cfiOmega$ values indicating different levels of qualitative model fit presents a problem for researchers who would like to generate population correlation matrices with fit indices indicating a particular degree of model fit. Choosing to use the $\textrm{TKL}_{\textrm{RMSEA}}$, CB, or WB methods would likely lead to correlation matrices with the desired $\rmseaOmega$ values for most conditions, but unacceptably low $\cfiOmega$ values. On the other hand, choosing to use the $\textrm{TKL}_{\textrm{CFI}}$ or $\textrm{TKL}_{\textrm{RMSEA/CFI}}$ would lead to almost the complete opposite problem; solutions would be likely to have observed $\cfiOmega$ values near the target values, but would also be likely to have smaller-than-desired $\rmseaOmega$ values. 

To determine which of the model-error methods led to the highest rates of fit index agreement, I evaluated fit index agreement in two ways. First, I evaluated each model error method in terms of the sum of the absolute differences between the observed and target $\rmseaOmega$ and $\cfiOmega$ values, defined as $D$ in \autoref{eq:distance-between-observed-and-target}. When evaluated on this criterion, the $\textrm{TKL}_{\textrm{CFI}}$ and $\textrm{TKL}_{\textrm{RMSEA/CFI}}$ methods led to much better results than the other investigated model-error methods, having the lowest median $D$ values over all conditions. Moreover, the $\textrm{TKL}_{\textrm{CFI}}$ and $\textrm{TKL}_{\textrm{RMSEA/CFI}}$ methods often led to much lower $D$ values than the alternatives (particularly in conditions with many factors, weak factor loadings, and Poor model fit) and rarely led to higher $D$ values. The second way I evaluated fit-index agreement was by using rule-of-thumb $\rmseaOmega$ and $\cfiOmega$ threshold values to categorize correlation matrices as having good, acceptable, or unacceptable model fit and then determining how often $\rmseaOmega$ and $\cfiOmega$ values led to the same level of qualitative model fit for each model-error method. The results of the simulation study indicated that the $\TKLcfi$ method was the most likely to produce solutions with qualitative model fit agreement, followed by the CB, $\TKLrmseacfi$, $\TKLrmsea$, and WB methods. These results suggest that the $\TKLcfi$ model is the best choice (of the model-error methods considered here) for researchers who would like to generate correlation matrices with model error and who would like to ensure that the matrices they generate have $\rmseaOmega$ and $\cfiOmega$ values that indicate the same level of qualitative model fit. However, it is also important to note that in many conditions (e.g., in conditions with many factors, Weak factor loadings, and Poor model fit), all of the model-error methods had qualitative fit agreement rates close to zero.

The result that the $\TKLcfi$ method led to both the smallest average $D$ values and the highest rate of qualitative fit agreement (using $\rmseaOmega$ and $\cfiOmega$) was quite surprising. Before conducting the simulation study, I predicted that the $\TKLrmseacfi$ method would lead to both the smallest $D$ values and the highest rates of qualitative fit agreement because it incorporated both target $\rmseaOmega$ and $\cfiOmega$ values. However, the simulation study results indicated that $\cfiOmega$ values tended to change more quickly as a function of $\rmseaOmega$ values than *vice versa*, particularly for conditions with many factors, many items per factor, and strong factor loadings. Put another way, changing the TKL parameter values to produce a solution with an $\rmseaOmega$ value incrementally closer to the target value often resulted in a large change to the $\cfiOmega$ value. This provided a plausible explanation for why the $\TKLrmseacfi$ and $\TKLcfi$ methods often led to similar results. Namely, because $\cfiOmega$ values were more sensitive to changes to the TKL parameters than $\rmseaOmega$, the $\TKLrmseacfi$ solutions were primarily influenced by the $\cfiOmega$ targets (and thus often produced results similar to the $\TKLcfi$ method) despite the $\cfiOmega$ and $\rmseaOmega$ targets being weighted equally in the objective function. 

Based on the results of the simulation study, I recommend that researchers who want to generate population correlation matrices with a particular level of model fit (as indicated by $\rmseaOmega$ and $\cfiOmega$ values) should use the $\TKLcfi$ model-error method. I also recommend the $\TKLrmseacfi$ method as an acceptable alternative. This method produced lower rates of qualitative fit agreement compared to the $\TKLcfi$ method, but very similar results in terms of $D$. Although the $\TKLcfi$ method led to the smallest $D$ values for the particular combinations of $\rmseaOmega$ and $\cfiOmega$ target values included in this study, it is possible that the $\TKLrmseacfi$ method could lead to smaller $D$ values when different combinations of target $\rmseaOmega$ and $\cfiOmega$ values are used. I recommend that researchers experiment with both options before committing to use either in a particular study. 

Although the CB method led to the second-highest rate of qualitative model fit agreement, it also often led to substantially higher $D$ values compared to the $\TKLcfi$ and $\TKLrmseacfi$ model-error methods. Moreover, it had several drawbacks that keep me from recommending it for use in simulation studies. First, the CB method was prohibitively slow whenever $\bOmega$ was large (i.e., whenever there were many factors or items per factor). Using the CB method with 150-variable conditions was so time-consuming that I had to drop them from my simulation design. The fact that the CB method is time-consuming when $\bOmega$ is large was all the more problematic because the CB method often produced indefinite $\bSigma$ matrices in those conditions. As noted in \@ref(indefinite-matrices), indefinite $\bSigma$ matrices are unacceptable candidates for population correlation matrices with model error because all correlation and covariance matrices are at least positive semi-definite by definition [@wothke1993; @lorenzo-seva2020a; @kracht2022]. Researchers hoping to obtain positive semi-definite $\bSigma$ matrices using the CB method with large $\bOmega$ matrices could simply generate a large number of solutions, rejecting indefinite $\bSigma$ matrices. However, given the completion time of the CB method and the high rates of indefinite solutions reported for many conditions of the simulation study, this is unlikely to be a feasible approach. Finally, it is unclear whether all of the desiderata of the CB method are, in fact, desirable. Specifically, it is not self-evident that the vector of population parameters should be perfectly recovered when the model is applied to $\bSigma$ using maximum likelihood (as it is in the CB method). Certainly, this constraint is not enforced by any of the alternative model-error methods. Even if a researcher finds the constraint reasonable and chooses to use the CB method as a result, the simulation results showed that the CB method often failed to find a solution such that $\bOmegaHat = \bOmega$ in some conditions.

Most of the issues associated with the CB method did not affect the $\TKLrmsea$ or WB model-error methods. For instance, neither method produced indefinite $\bSigma$ matrices and both methods had much shorter completion times compared with the CB method. However, I do not recommend either model error method for general use in simulation studies. Both the $\TKLrmsea$ and WB methods led to relatively high $D$ values and relatively low rates of qualitative model fit agreement compared to the alternative model-error methods. Additionally, the $\TKLrmsea$ method often led to solutions with strong minor factors that would more appropriately be considered major factors. Even the inclusion of a large penalty term ($\lambda$) did not prevent the $\TKLrmsea$ method from producing solutions that violated the constraint that no minor factor should have more than two absolute loadings greater than 0.3. On the other hand, the $\TKLcfi$ or $\TKLrmseacfi$ methods seldom led to solutions that violated the minor factor constraints. In fact, the $\TKLcfi$ and $\TKLrmseacfi$ methods did not produce solutions that violated the minor factor constraints even when $\lambda = 0$ (i.e., when no penalty was applied). Thus, the study results indicated that the inclusion of a reasonable target $\cfiOmega$ value was almost always sufficient to avoid generating solutions with strong minor factors. Researchers who want to use the $\TKLrmsea$ method could discard solutions that violated the minor factor constraints and continue generating new solutions until a sufficient number of acceptable solutions were found. However, the study results indicated the $\TKLrmsea$ method almost always led to solutions that violated the minor factor constraints in conditions with many factors, many items per factor, and Poor model fit. Therefore, the strategy of discarding solutions that violated the minor factor constraints is likely to be highly inefficient (if not completely impractical) for those conditions.

## Limitations and Future Work

As with any study, I acknowledge that the simulation study reported in this dissertation was subject to certain limitations. For instance, I designed the study to include a wide range of models that might plausibly be encountered in psychological research. However, there were still many types of models that were not included in the study design. For instance, the study design only included models with equal numbers of salient items per factor, all factor correlations fixed at the same value, and all non-zero factor loadings fixed at the same value. Although these models were artificially simple, they were chosen because they made it easier to isolate the effects of each of the independent variables (e.g., number of factors, number of items per factor, factor loading, etc.) and because similar models have been used in previous Monte Carlo studies [@kracht2022; @debelak2016; @debelak2013; @auerswald2019]. Nevertheless, future research should investigate how the results from the CB, WB, and TKL-based model-error methods differ when used with more complex models. The implementations of these model error methods in the *noisemaker* R package, along with the simulation code in \@ref(main-simulation) should facilitate this future work.

Another limitation of the present study was that it investigated model error only in the context of factor analysis models and not covariance structure models more generally. The choice to focus on factor analysis models was largely motivated by the fact that the TKL method is specific to the factor analysis model. Unlike the CB and WB model-error methods, which can be used with any covariance structure model, the TKL method requires modification to be applied to covariance structure models other than the common factor model [e.g., @trichtinger2020]. Where possible, it would be useful to extend the TKL method (and the multiple-objective TKL method) to additional types of covariance structure models. It might also be useful to investigate whether automated procedures could be developed to incorporate target $\cfiOmega$ values into the CB or WB methods. For instance, the target $\rmseaOmega$ value used in the CB and WB methods could be treated as a tuning parameter and optimized to find the value that leads to solutions with $\cfiOmega$ values that are close to a user-specified target value. As with the multiple-objective TKL method, users could also specify how much weight to give each fit index. Although evaluating the CB method many times in an optimization loop is likely to be prohibitively time-consuming with large models, the procedure could work well for the WB method (or for the CB method when models are small). Future work should investigate the effectiveness of optimizing CB and WB target $\rmseaOmega$ values to incorporate $\cfiOmega$ targets.

A second limitation of the present study is that it primarily compared the outputs of model-error methods in terms of model fit indices. However, $\bSigma$ matrices generated using different model-error methods might differ in important ways, even if the matrices they produce have similar model fit indices. For instance, $\bSigma$ matrices generated using different model-error methods might not lead to identical parameter estimates when used in factor analysis, even if the fit indices for both matrices are similar. If that is the case, it would indicate that the choice of model-error method is important when conducting simulation studies. Additional research should address this issue.

Research comparing model-error methods and investigating the impact of model error on fitting covariance structure models will benefit from flexible, robust, and easy-to-use implementations of model-error methods. The *noisemaker* package (and the function of the same name) that was developed as a part of this dissertation provides a simple, unified interface for generating correlation matrices with model error using the new multiple-objective TKL method, the CB method, and WB method. Moreover, the *noisemaker* handles specification of the population model (without model error) using the `simFA()` function from the *fungible* package. Together, the *noisemaker* and *fungible* packages provide a powerful collection of functions for researchers who wish to simulate factor analysis models and data sets. 

Future work should continue to improve the *noisemaker* package by adding features and improving ease of use. For example, an update to the `noisemaker()` function has been planned that will let users specify allowable ranges of $\epsilon$ and $\nu_{\textrm{e}}$ parameters when using the multiple-objective TKL method. Although it is difficult to know which precise values of $\epsilon$ and $\nu_\textrm{e}$ are reasonable for a particular model, it is sometimes possible to specify plausible ranges of these parameters. For instance, consider a population model with one major common factor and ten items, each with a factor loading of 0.8. The major common factor, therefore, accounts for 64% of the variance in each item. Setting $\nu_\textrm{e} = .75$ would then mean that 91% of the item variance would be accounted for by the (reliable) major and minor common factors. In some contexts, this might be reasonable; in many psychological contexts, it would be considered unreasonable. Similarly, a researcher might consider it unlikely that all of the minor factors should be equally strong. In that case, values of $\epsilon$ very close to zero would be considered unrealistic. To allow users to specify allowable ranges of $\epsilon$ and $\nu_\textrm{e}$ for the multiple-objective TKL method, those ranges could be used as the parameter boundary constraints in the L-BFGS-B algorithm instead of $\epsilon, \nu_\textrm{e} \in [0,1]$. This feature has already been implemented in a development version of *noisemaker*[^noisemaker-dev] that will be submitted to CRAN once testing has been completed.

[^noisemaker-dev]: The most recent development version of the *noisemaker* package is available at [github.com/JustinKracht/noisemaker](https://www.github.com/JustinKracht/noisemaker), along with a vignette demonstrating how it can be used.

In conclusion, the work in this dissertation should provide a valuable resource for researchers who would like to incorporate model error into Monte Carlo simulation studies of factor analysis models. I have reported an overview of existing model-error methods and have proposed an extension of the TKL model-error method that allows researchers to specify target $\rmseaOmega$ values, target $\cfiOmega$ values, or both simultaneous. By conducting an extensive simulation study, I showed that using the proposed multiple-target TKL method with target $\rmseaOmega$ and $\cfiOmega$ values (or with only a target $\cfiOmega$ value) often led to solutions with better quantitative and qualitative fit index agreement compared to the alternative model-error methods. Finally, I developed the R *noisemaker* package to make it easy for researchers to use any of the model-error methods investigated in this simulation study. 
