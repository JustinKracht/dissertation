
# Discussion {#discussion}

In this dissertation, I conducted a large-scale simulation study to compare several methods for simulating population correlation matrices with model error. The model-error methods I compared were the Cudeck and Browne [CB\; -@cudeck1992] method, the Wu and Browne [WB\; -@wu2015] method, and three variations of the Tucker, Koopman, and Linn [TKL\; -@tucker1969] model-error method using a novel optimization procedure to automatically select values of the TKL method parameters, $\epsilon$ and $\nu_{\textrm{e}}$. The addition of the optimization procedure allowed the TKL method to be used with specified target values of RMSEA (the $\textrm{TKL}_{\textrm{RMSEA}}$ variation), CFI (the $\textrm{TKL}_{\textrm{CFI}}$ variation), or both fit indices simultaneously (the $\textrm{TKL}_{\textrm{RMSEA/CFI}}$ variation). Moreover, the optimization procedure also allowed users to impose constraints on the loadings of the minor common factors introduced by the TKL method to ensure that there was a clear delineation between major and minor common factors. To facilitate the use of all of the model-error methods discussed in this dissertation, I also developed an R package (*noisemaker*) that serves as an easy-to-use, unified interface for simulating correlation matrices with model error.

Through this simulation study, I hoped to answer two primary questions about the model-error methods I investigated. First, I wanted to know whether the five model-error methods included in the study (the $\textrm{TKL}_{\textrm{RMSEA}}$, $\textrm{TKL}_{\textrm{CFI}}$, $\textrm{TKL}_{\textrm{RMSEA/CFI}}$, CB, and WB methods) led to different values of the CFI, TLI, and CRMR fit indices when used with the same error-free population correlation matrices and target RMSEA values. If all of the model-error methods led to the same (or similar) fit index values, it would have suggested that the choice of which model-error method to use is not very important when conducting simulation studies involving covariance structure models. The second question I wanted to answer was related to the efficacy of the modified TKL method with the proposed optimization procedure (referred to as the multiple-target TKL method). That is, I was interested in determining how well the multiple-target TKL method was able to generate correlation matrices with model error that had RMSEA and CFI values that were close to the specified values. Note that in the following discussion of the simulation results I focus on the RMSEA and CFI fit indices for two reasons. First, RMSEA and CFI target values were used in the simulation study and are often used as indications of model fit when generating population correlation matrices with model error [@tucker1969; @cudeck1992; @kracht2022; @trichtinger2020]. Second, the CRMR and TLI indices led to results that were similar to the results for RMSEA and CFI, respectively.

Concerning the first primary research question, the results indicated that there were important differences between the five model-error methods in terms of the observed model fit indices they led to. Although all of the model-error methods led to similar RMSEA, CFI, TLI, and CRMR values in conditions with few major factors, strong factor loadings, and good model fit, they led to much more disparate results in other conditions. In particular, the results of the simulation study indicated that there were important differences between model-error methods that incorporated only a target RMSEA value (i.e., the $\textrm{TKL}_{\textrm{RMSEA}}$, CB, and WB methods) and methods that incorporated a target CFI value (the $\textrm{TKL}_{\textrm{CFI}}$ and $\textrm{TKL}_{\textrm{RMSEA/CFI}}$ methods). 

When evaluated on RMSEA, the model-error methods that only incorporated target RMSEA values generally produced solutions with observed RMSEA values very close to the target values. In particular, the $\textrm{TKL}_{\textrm{RMSEA}}$ and CB methods led to RMSEA values that almost always extremely close to the target values, whereas there was slightly more variability in the RMSEA values from the WB method. On the other hand, the model-error methods that incorporated CFI target values often led to RMSEA values that were lower than the target values, particularly in conditions with many major common factors and weak factor loadings. The result that the $\textrm{TKL}_{\textrm{RMSEA}}$, CB, and WB model-error methods led to solutions with RMSEA values that were close to the target values is perhaps unsurprising, given that this was what all three methods were designed to do. However, it confirms that the CB method worked as expected and provides evidence that the  modifications of the TKL and WB methods to incorporate target RMSEA values were successful. On the other hand, the $\TKLrmsea$ and $\TKLrmseacfi$ methods both led to solutions with RMSEA values that were further from the target RMSEA values in most conditions, particularly when model fit was Poor or when there were many major common factors.

When evaluated on CFI, the two model-error methods that incorporated target CFI values ($\textrm{TKL}_{\textrm{CFI}}$ and $\textrm{TKL}_{\textrm{RMSEA/CFI}}$) generally produced observed CFI values that were closer to the target values than the other model error methods. Although all of the model-error methods led to observed CFI values that were close the target values in conditions with strong factor loadings and Very Good model fit, the $\textrm{TKL}_{\textrm{RMSEA}}$, CB, and WB methods often led to unacceptably low CFI values in other conditions. Interestingly, the $\TKLcfi$ and $\TKLrmseacfi$ methods often led to quite similar results, despite the $\TKLrmseacfi$ method incorporating a target RMSEA value. This seemed to be because CFI was more sensitive to changes in parameter values compared to RMSEA, particularly in conditions with many factors, many items per factor, and low factor loadings. A small change in parameter values that produced an RMSEA value slightly closer to the target value often resulted in a large change in CFI away from the target value. Correspondingly, small changes in parameter values that produced a CFI value closer to the target value generally had only a small effect on the RMSEA value. As a result, the $\TKLrmseacfi$ method tended to "prioritize" target CFI values, despite both RMSEA and CFI being weighted equally in the objective function.

The result that the $\textrm{TKL}_{\textrm{CFI}}$ and $\textrm{TKL}_{\textrm{RMSEA/CFI}}$ methods led to RMSEA values that were often far from the target suggested a problem with using only target RMSEA values to generate correlation matrices with model error. Namely, the problem was that solutions with RMSEA values that were close to target RMSEA values often had CFI values that indicated a worse qualitative level of model fit. For instance, in conditions with five factors, weak factor loadings, and Very Good (target) model fit, the $\textrm{TKL}_{\textrm{RMSEA}}$ method produced solutions with RMSEA values that were very close to the target RMSEA value of 0.025. However, none of corresponding CFI values for those solutions reached the target value of .99 (considered to represent Very Good model fit), and many CFI values were below .90 (a liberal threshold for acceptable model fit). These results indicate that using RMSEA alone to adjudicate model fit makes it not only possible, but *likely* that simulated population correlation matrices would be included in conditions with nominally excellent model fit as indicated by RMSEA values, but with unacceptably poor model fit as indicated by CFI values. These results agreed with results reported by Kracht and Waller [-@kracht2022], who used the TKL method with manually-selected parameter values to produce matrices with RMSEA values in a particular range. They found that although they were able to select parameter values that led to solutions with RMSEA values in the desired ranges, the CFI values for those solutions were often below the standard cutoff values. Furthermore, they reported that CFI values were lowest in conditions with many items, low factor loadings, and poor model fit.

The fact that all of the model error method often produced solutions with RMSEA and CFI values indicating different levels of qualitative model fit presents a problem for researchers who would like to generate population correlation matrices with fit indices indicating a particular degree of model fit. Choosing to use the $\textrm{TKL}_{\textrm{RMSEA}}$, CB, or WB methods would likely lead to correlation matrices with the desired RMSEA values for most conditions, but unacceptably low CFI values. On the other hand, choosing to use the $\textrm{TKL}_{\textrm{CFI}}$ or $\textrm{TKL}_{\textrm{RMSEA/CFI}}$ would lead to almost the complete opposite problem; solutions would be likely to have observed CFI values near the target values, but would also be likely to have smaller-than-desired RMSEA values. 

To determine which of the model-error methods led to the highest rates of fit index agreement, I evaluated fit index agreement in two ways. First, I evaluated each model error method in terms of the sum of the absolute differences between the observed and target RMSEA and CFI values, defined as $D$ in \autoref{eq:distance-between-observed-and-target}. When evaluated on this criterion, the $\textrm{TKL}_{\textrm{CFI}}$ and $\textrm{TKL}_{\textrm{RMSEA/CFI}}$ methods led to much better results than the other investigated model-error methods, having the lowest median $D$ values over all conditions. Moreover, the $\textrm{TKL}_{\textrm{CFI}}$ and $\textrm{TKL}_{\textrm{RMSEA/CFI}}$ methods often led to much lower $D$ values than the alternatives (particularly in conditions with many factors, weak factor loadings, and Poor model fit) and rarely led to higher $D$ values. The second way I evaluated fit-index agreement was by using rule-of-thumb RMSEA and CFI threshold values to categorize correlation matrices as having good, acceptable, or unacceptable model fit and then determining how often RMSEA and CFI values led to the same level of qualitative model fit for each model-error method. The results of the simulation study indicated that the $\TKLcfi$ method was the most likely to produce solutions with qualitative model fit agreement, followed by the CB, $\TKLrmseacfi$, $\TKLrmsea$, and WB methods. These results suggest that the $\TKLcfi$ model is the best choice (of the model-error methods considered here) for researchers who would like to generate correlation matrices with model error and who would like to ensure that the matrices they generate have RMSEA and CFI values that indicate the same level of qualitative model fit. However, it is also important to note that in many conditions (e.g., in conditions with many factors, Weak factor loadings, and Poor model fit), all of the model-error methods had qualitative fit agreement rates close to zero.

The result that the $\TKLcfi$ method led to both the smallest average $D$ values and the highest rate of qualitative fit agreement (using RMSEA and CFI) was quite surprising. Before conducting the simulation study, I predicted that the $\TKLrmseacfi$ method would lead to both the smallest $D$ values and the highest rates of qualitative fit agreement because it incorporated both target RMSEA and CFI values. However, the simulation study results indicated that CFI values tended to change more quickly as a function of RMSEA values than *vice versa*, particularly for conditions with many factors, many items per factor, and strong factor loadings. Put another way, changing the TKL parameter values to produce a solution with an RMSEA value incrementally closer to the target value often resulted in a large change to the CFI value. This provided a plausible explanation for why the $\TKLrmseacfi$ and $\TKLcfi$ methods often led to similar results. Namely, because CFI values were more sensitive to changes to the TKL parameters than RMSEA, the $\TKLrmseacfi$ solutions were primarily influenced by the CFI targets (and thus often produced results similar to the $\TKLcfi$ method) despite the CFI and RMSEA targets being weighted equally in the objective function. 

Based on the results of the simulation study, I recommend that researchers who want to generate population correlation matrices with a particular level of model fit (as indicated by RMSEA and CFI values) should use the $\TKLcfi$ model-error method. I also recommend the $\TKLrmseacfi$ method as an acceptable alternative. This method produced lower rates of qualitative fit agreement compared to the $\TKLcfi$ method, but very similar results in terms of $D$. Although the $\TKLcfi$ method led to the smallest $D$ values for the particular combinations of RMSEA and CFI target values included in this study, it is possible that the $\TKLrmseacfi$ method might lead to smaller $D$ values when different combinations of target RMSEA and CFI values are used. I recommend that researchers experiment with both options before committing to use either in a particular study. 

Although the CB method led to the second-highest rate of qualitative model fit agreement, it also often led to substantially higher $D$ values compared to the $\TKLcfi$ and $\TKLrmseacfi$ model-error methods. Moreover, it had several drawbacks that keep me from recommending it for use in simulation studies. First, the CB method was prohibitively slow whenever $\bOmega$ was large (i.e., whenever there were many factors or items per factor).  Using the CB method with 150-variable conditions was so time-consuming that I had to drop them from my simulation design. The fact that the CB method is time consuming when $\bOmega$ is large was all the more problematic because the CB method often produced indefinite $\bSigma$ matrices in those conditions. As noted in \@ref(indefinite-matrices), indefinite $\bSigma$ matrices are unacceptable candidates for population correlation matrices with model error because all correlation and covariance matrices are at least positive semi-definite by definition [@wothke1993; @lorenzo-seva2020a; @kracht2022]. Researchers hoping to obtain positive semi-definite $\bSigma$ matrices using the CB method with large $\bOmega$ matrices could simply generate a large number of solutions, rejecting indefinite $\bSigma$ matrices. However, given the completion time of the CB method and the high rates of indefinite solutions reported for many conditions of the simulation study, this is unlikely to be a feasible approach. Finally, it is unclear whether all of the desiderata of the CB method are, in fact, desirable. Specifically, it is not self-evident that the vector of population parameters should be perfectly recovered when the model is applied to $\bSigma$ using maximum likelihood (as it is in the CB method). Certainly, this constraint is not enforced by any of the alternative model-error methods. Even if a researcher finds the constraint reasonable and chooses to use the CB method as a result, the simulation results showed that the CB method often failed to find a solution such that $\bOmegaHat = \bOmega$ in some conditions.

Most of the issues associated with the CB method did not affect the $\TKLrmsea$ or WB model-error methods. For instance, neither method produced indefinite $\bSigma$ matrices and both methods had much shorter completion times compared with the CB method. However, I do not recommend either model error method for general use in simulation studies. Both the $\TKLrmsea$ and WB methods led to relatively high $D$ values and relatively low rates of qualitative model fit agreement compared to the alternative model-error methods. Additionally, the $\TKLrmsea$ method often led to solutions with strong minor factors that would more appropriately be considered major factors. Even the inclusion of a large penalty term ($\lambda$) did not prevent the $\TKLrmsea$ method from producing solutions that violated the constraint that no minor factor should have more than two absolute loadings greater than 0.3. On the other hand, the $\TKLcfi$ or $\TKLrmseacfi$ methods almost never led to solutions that violated the minor factor constraints. In fact, the $\TKLcfi$ and $\TKLrmseacfi$ methods did not produce solutions that violated the minor factor constraints even when $\lambda = 0$ (i.e., when no penalty was applied). Thus, the study results indicated that the inclusion of a reasonable target CFI value was almost always sufficient to avoid generating solutions with strong minor factors. Researchers who want to use the $\TKLrmsea$ method could discard solutions that violated the minor factor constraints and continue generating new solutions until a sufficient number of acceptable solutions were found. However, the study results indicated the $\TKLrmsea$ method almost always led to solutions that violated the minor factor constraints in conditions with many factors, many items per factor, and Poor model fit. Therefore, the strategy of discarding solutions that violated the minor factor constraints is likely to be highly inefficient (if not completely impractical) for those conditions.

## Limitations and Future Work

As with any study, I acknowledge that the simulation study reported in this dissertation was subject to certain limitations. For instance, I designed the study to include a wide range of models that might plausibly be encountered in psychological research. However, there were still many types of models that were not included in the study design. For instance, the study design only included models with equal numbers of salient items per factor, all factor correlations fixed at the same value, and all non-zero factor loadings fixed at the same value. Although these models were artificially simple, they were chosen because they made it easier to isolate the effects of each of the independent variables (e.g., number of factors, number of items per factor, factor loading, etc.) and because similar models have been used in previous Monte Carlo simulation studies [@kracht2022; @debelak2016; @debelak2013; @auerswald2019]. Nevertheless, future research should investigate how the results from the CB, WB, and TKL-based model-error methods differ when used with more complex models. The implementations of these model error methods in the *noisemaker* R package, along with the simulation code in \@ref(main-simulation) should facilitate this future work.

A second limitation of the present study was that it only investigated model error only in the context of factor analysis models and not covariance structure models more generally. The choice to focus on factor analysis models was largely motivated by the fact that the TKL method is specific to the factor analysis model. Unlike the CB and WB model-error methods, which can be used with any covariance structure model, the TKL method requires modification to be applied to covariance structure models other than the common factor model [e.g., @trichtinger2020]. Where possible, it would be useful to extend the TKL method (and the multiple-objective TKL method) to additional types of covariance structure models. It might also be useful to investigate whether automated procedures could be developed to incorporate target CFI values into the CB or WB methods. For instance, the target RMSEA value used in the CB and WB methods could be treated as a tuning parameter and optimized to find the value that leads to solutions with CFI values that are close to a user-specified target value. As with the multiple-objective TKL method, users could also specify how much weight to give each fit index. Although evaluating the CB method many times in an optimization loop is likely to be prohibitively time-consuming with large models, the procedure could work well for the WB method (or for the CB method when models are small). Future work should investigate the effectiveness of optimizing CB and WB target RMSEA values to incorporate CFI targets.

In addition to extending the simulation design and investigating ways to incorporate CFI targets in the CB and WB methods, future work should be done to build and improve flexible, robust, and easy-to-use implementations of model-error methods for use in Monte Carlo simulation studies. The *noisemaker* package (and the function of the same name) that was developed as a part of this dissertation provides a simple, unified interface for generating correlation matrices with model error using the new multiple-objective TKL method, the CB method, and WB method. Moreover, the *noisemaker* handles specification of the population model (without model error) using the `simFA()` function from the *fungible* package. Together, the *noisemaker* and *fungible* packages provide a powerful collection of functions for researchers who wish to simulate factor analysis models and data sets. 

Future work should continue to improve the *noisemaker* package by adding features and improving ease-of-use. For example, an update to the `noisemaker()` function has been planned that will let users to specify allowable ranges of $\epsilon$ and $\nu_{\textrm{e}}$ parameters when using the multiple-objective TKL method. Although it is difficult to know which precise values of $\epsilon$ and $\nu_\textrm{e}$ are reasonable for a particular model, it is sometimes possible to specify plausible ranges of these parameters. For instance, consider a population model with one major common factor and ten items, each with a factor loading of 0.8. The major common factor therefore accounts for 64% of the variance in each item. Setting $\nu_\textrm{e} = .75$ would then mean that 91% of the item variance would be accounted for by the (reliable) major and minor common factors. In some contexts, this might be reasonable; in many psychological contexts, it would be considered unreasonable. Similarly, a researcher might consider it unlikely that all of the minor factors should be equally strong. In that case, values of $\epsilon$ very close to zero would be considered unrealistic. To allow users to specify allowable ranges of $\epsilon$ and $\nu_\textrm{e}$ for the multiple-objective TKL method, those ranges could be used as the parameter boundary constraints in the L-BFGS-B algorithm instead of $\epsilon, \nu_\textrm{e} \in [0,1]$. This feature has already been implemented in a development version of *noisemaker*[^noisemaker-dev] that will be submitted to CRAN once testing has been completed. 

[^noisemaker-dev]: The most recent development version of the *noisemaker* package is available at [github.com/JustinKracht/noisemaker](https://www.github.com/JustinKracht/noisemaker), along with a vignette demonstrating how it can be used.

In conclusion, the work in this dissertation should provide a valuable resource for researchers who would like to incorporate model error into Monte Carlo simulation studies of factor analysis models. I have reported an overview of existing model-error methods and have proposed an extension of the TKL model-error method that allows researchers to specify target RMSEA values, target CFI values, or both simultaneous. By conducting an extensive simulation study, I showed that using the proposed multiple-target TKL method with target RMSEA and CFI values (or with only a target CFI value) often led to solutions with better quantitative and qualitative fit index agreement compared to the alternative model-error methods. Finally, I developed the R *noisemaker* package to make it easy for researchers to use any of the model-error methods investigated in this simulation study. 