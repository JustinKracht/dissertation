
# Discussion {#discussion}

In this dissertation, I conducted a large-scale simulation study to compare several methods for simulating population correlation matrices with model error. The model-error methods I compared were the Cudeck and Browne [CB\; @cudeck1992] method, the Wu and Browne [WB\; @wu2015] method, and three variations of the Tucker, Koopman, and Linn [TKL\; @tucker1969] model-error method using a novel optimization procedure to automatically select values of the TKL method parameters, $\epsilon$ and $\nu_{\textrm{e}}$. The addition of the optimization procedure allowed the use of the TKL method with specified target values of RMSEA (the $\textrm{TKL}_{\textrm{RMSEA}}$ variation), CFI (the $\textrm{TKL}_{\textrm{CFI}}$ variation), or both fit indices simultaneously (the $\textrm{TKL}_{\textrm{RMSEA/CFI}}$ variation). Moreover, the optimization procedure also allowed users to impose constraints on the loadings of the minor common factors introduced by the TKL method to ensure that there was a clear delineation between major and minor common factors. To facilitate the use of all of the model-error methods discussed in this dissertation, I also developed an R package (*noisemaker*) that serves as an easy-to-use, unified interface for simulating correlation matrices with model error.

Through the simulation study I conducted, I hoped to answer two primary questions about the model-error methods I investigated. First, I wanted to know whether the five model-error methods included in the study (the $\textrm{TKL}_{\textrm{RMSEA}}$, $\textrm{TKL}_{\textrm{CFI}}$, $\textrm{TKL}_{\textrm{RMSEA/CFI}}$, CB, and WB methods) led to different values of the CFI, TLI, and CRMR fit indices when used with the same error-free population correlation matrices and target RMSEA values. If all of the model-error methods led to the same (or similar) fit index values, it would have suggested that the choice of which model-error method to use is not very important when conducting simulation studies involving covariance structure models. The second question I wanted to answer was how effective the modified TKL method with the proposed optimization procedure (referred to as the multiple-target TKL method) worked. That is, I was interested in determining how well the multiple-target TKL method was able to generate correlation matrices with model error that had RMSEA and CFI values that were close to the specified values. Note that in the following discussion of the simulation results I focus on the RMSEA and CFI fit indices for two reasons. First, RMSEA and CFI target values were used in the simulation study and are often used as indications of model fit when generating population correlation matrices with model error [@tucker1969; @cudeck1992; @kracht2020; @trichtinger2020]. Second, the CRMR and TLI indices led to results that were similar to the results in terms of RMSEA and CFI, respectively.

Concerning the first primary research question, the results of my simulation study indicated that there were important differences between the five model-error methods in terms of the observed model fit indices they led to. Although all of the model-error methods led to similar RMSEA, CFI, TLI, and CRMR values in conditions with few major factors, strong factor loadings, and good model fit, they led to much more disparate results in other conditions. In particular, the results of the simulation study indicated that there were important differences between model-error methods that (a) incorporated only a target RMSEA value (i.e., the $\textrm{TKL}_{\textrm{RMSEA}}$, CB, and WB methods), (b) incorporated only a target CFI value (the $\textrm{TKL}_{\textrm{CFI}}$ method), or (c) incorporated both RMSEA and CFI target values (the $\textrm{TKL}_{\textrm{RMSEA/CFI}}$ method). 

When evaluated on RMSEA, the model-error methods that only incorporated target RMSEA values generally produced solutions with observed RMSEA values very close to the target values. In particular, the $\textrm{TKL}_{\textrm{RMSEA}}$ and CB methods led to RMSEA values that almost always extremely close to the target values, whereas there was slightly more variability in the RMSEA values from the WB method. On the other hand, the model-error methods that incorporated CFI target values often led to RMSEA values that were lower than the target values, particularly in conditions with many major common factors and weak factor loadings. The result that the $\textrm{TKL}_{\textrm{RMSEA}}$, CB, and WB model-error methods led to solutions with RMSEA values that were close to the target values is perhaps unsurprising, given that this was what all three methods were designed to do. However, it confirms that the CB method worked as expected and provides evidence that the  modifications of the TKL and WB methods to incorporate target RMSEA values were successful. 

When evaluated on CFI, the two model-error methods that incorporated target CFI values ($\textrm{TKL}_{\textrm{CFI}}$ and $\textrm{TKL}_{\textrm{RMSEA/CFI}}$) generally produced observed CFI values that were closer to the target values than the other model error methods. Although all of the model-error methods led to observed CFI values that were close the target values in conditions with strong factor loadings and Very Good model fit, the $\textrm{TKL}_{\textrm{RMSEA}}$, CB, and WB methods often led to unacceptably low CFI values in other conditions. 

The result that the $\textrm{TKL}_{\textrm{CFI}}$ and $\textrm{TKL}_{\textrm{RMSEA/CFI}}$ methods led to RMSEA values that were often far from the target suggested a problem with using only target RMSEA values to generate correlation matrices with model error. Namely, the problem was that solutions with RMSEA values that were close to target RMSEA values often had CFI values that indicated a worse qualitative level of model fit. For instance, in conditions with five factors, weak factor loadings, and Very Good (target) model fit, the $\textrm{TKL}_{\textrm{RMSEA}}$ method produced solutions with RMSEA values that were very close to the target RMSEA value of .025. However, none of corresponding CFI values for those solutions reached the target value of .99 (considered to represent Very Good model fit), and many CFI values were below .90 (a liberal threshold for acceptable model fit). These results indicate that using RMSEA alone to adjudicate model fit makes it not only possible, but *likely* that simulated population correlation matrices would be included in conditions with nominally excellent model fit as indicated by RMSEA values, but with unacceptably poor model fit as indicated by CFI values. 

This presents a problem for researches who would like to generate population correlation matrices with fit indices indicating a particular degree of model fit. Choosing to use the $\textrm{TKL}_{\textrm{RMSEA}}$, CB, or WB methods would likely lead to correlation matrices with the desired RMSEA values for most conditions, but unacceptably low CFI values. On the other hand, choosing to use the $\textrm{TKL}_{\textrm{CFI}}$ or $\textrm{TKL}_{\textrm{RMSEA/CFI}}$ would lead to almost the complete opposite problem; solutions would be likely to have observed CFI values near the target values, but would also be likely to have smaller-than-desired RMSEA values. To determine which of the model-error methods led to the highest rates of fit index agreement, I evaluated fit index agreement in two ways. First, I evaluated each model error method in terms of the sum of the absolute differences between the observed and target RMSEA and CFI values, defined as $D$ in \autoref{eq:distance-between-observed-and-target}. When evaluated on this criterion, the $\textrm{TKL}_{\textrm{CFI}}$ and $\textrm{TKL}_{\textrm{RMSEA/CFI}}$ led to the best results out of all of the investigated model-error methods. Specifically, the $\textrm{TKL}_{\textrm{CFI}}$ and $\textrm{TKL}_{\textrm{RMSEA/CFI}}$ methods often led to much lower $D$ values than the alternatives (particularly in conditions with many factors, weak factor loadings, and Poor model fit) and rarely led to higher $D$ values. 

The second way I evaluated fit-index agreement was by using rule-of-thumb RMSEA and CFI threshold values to categorize correlation matrices as having good, acceptable, or unacceptable model fit and then determining how often RMSEA and CFI values led to the same level of qualitative model fit for each model-error method. The results of the simulation study indicated that the $\textrm{TKL}_{\textrm{RMSEA/CFI}}$ method was most likely to produce solutions with qualitative model fit agreement, followed by the CB, $\textrm{TKL}_{\textrm{RMSEA/CFI}}$, $\textrm{TKL}_{\textrm{RMSEA}}$, and WB methods. 

These results coincide with results reported by Kracht and Waller [-@kracht2020], who found that using the TKL method to generate correlation matrices with model error often resulted in RMSEA and CFI values indicating different levels of qualitative model fit.

<!---
Find a way to work in: all methods led to similar results (in terms of RMSEA, CFI, CRMR, and TLI) in conditions with few factors, strong factor loadings, and very good model fit. However, the methods led to very different results in conditons with many major factors, relatively weak factor loadings, and poor model fit.

1. Model-error methods led to different outcomes in terms of RMSEA and CFI values.
  a. RMSEA
    i. The model-error methods that only used RMSEA targets led to (unsurprisingly) similar results in terms of RMSEA. In paricular, the TKL_RMSEA, and CB methods both produced solutions with RMSEA values that were very close to the target RMSEA values. The distributions of observed RMSEA values for the solutions produced by the WB method were centered around the target RMSEA value, but were more variable than the RMSEA distributions for the TKL_RMSEA and CB methods.
    ii. On the other hand, the TKL_CFI, and TKL_RMSEA_CFI methods typically led to observed RMSEA values that were not as close to the target RMSEA values. In many cases, TKL_CFI, and TKL_RMSEA_CFI led to RMSEA values that were somewhat lower than the target values, particularly in conditions with many factors. 
  b. CFI
    i. When evaluated on CFI, the model-error methods again fell into groups according to whether or not they incorporated a CFI target value. 
    ...
    
2. When assessing which of these methods to use in simulation work, there are other considerations. (A) Completion time; (B) Non-convergence; (C) Indefinite Matrices.


Future Research:

1. More flexible targets; target fit index ranges rather than fit index values.
2. Marsh et al. in search of golden rules: use more varied (realistic) model error methods to establish rule-of-thumb cutoff values.
3. The proposed model-error methods will give researchers the ability to generate more realistic population models with model error and user-specified fit index values. This could help us better understand how fit indices 
--->

