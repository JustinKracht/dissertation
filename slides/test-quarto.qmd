---
title: 'Make Some Noise: Generating Data From Imperfect Models'
date: 'September 2022'
author: 'Justin Kracht'
institute: 'University of Minnesota'
format: 
  revealjs:
    theme: [default, custom.scss]
    logo: Msol-maroon.png
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache=TRUE, echo=FALSE)

pacman::p_load(bookdown,
               tidyverse,
               latex2exp,
               noisemaker,
               bookdown,
               papaja,
               here)

make_plots <- FALSE # regenerate plots?
```

## Presentation Overview

$$
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\dg}{\textrm{dg}}
\DeclareMathOperator{\vech}{vec}
\DeclareMathOperator{\RMSEA}{\textrm{RMSEA}}
\newcommand{\TKLrmseacfi}{\textrm{TKL}_{\textrm{RMSEA} / \textrm{CFI}}}
\newcommand{\TKLrmsea}{\textrm{TKL}_{\textrm{RMSEA}}}
\newcommand{\TKLcfi}{\textrm{TKL}_{\textrm{CFI}}}
\newcommand{\rmseaOmega}{\textrm{RMSEA}_{\boldsymbol{\Omega}}}
\newcommand{\cfiOmega}{\textrm{CFI}_{\boldsymbol{\Omega}}}
\newcommand{\tliOmega}{\textrm{TLI}_{\boldsymbol{\Omega}}}
\newcommand{\crmrOmega}{\textrm{CRMR}_{\boldsymbol{\Omega}}}
\newcommand{\rmseaOmegaHat}{\textrm{RMSEA}_{\hat{\boldsymbol{\Omega}}}}
\newcommand{\cfiOmegaHat}{\textrm{CFI}_{\hat{\boldsymbol{\Omega}}}}
\newcommand{\tliOmegaHat}{\textrm{TLI}_{\hat{\boldsymbol{\Omega}}}}
\newcommand{\crmrOmegaHat}{\textrm{CRMR}_{\hat{\boldsymbol{\Omega}}}}
\newcommand{\bgamma}{\boldsymbol{\gamma}}
\newcommand{\bSigma}{\boldsymbol{\Sigma}}
\newcommand{\bOmega}{\boldsymbol{\Omega}}
\newcommand{\bOmegaHat}{\hat{\boldsymbol{\Omega}}}
\newcommand{\rmseaDelta}{\textrm{RMSEA}_{\Delta}}
\newcommand{\cfiDelta}{\textrm{CFI}_{\Delta}}
$$

1. Background  
2. Methods for Simulating Model Error  
3. Quantifying Model Error  
4. Study Aims  
5. Methods  
6. Results  

::: {.notes}
1. Background: What is model error, and why does it matter?  
2. Simulating Model Error: What methods are available to simulate model error?  
3. Quantifying Model Error: What model fit indices are used to quantify model error, and how do they differ?  
4. Study Aims  
5. Methods  
6. Results 
:::

# Background

## Model Error and Covariance Structure Models

Covariance structure models allow a structured covariance matrix to be represented as a function of a vector of parameters,

\begin{equation}
\boldsymbol{\Omega} = \boldsymbol{\Omega}(\boldsymbol{\gamma}),
\end{equation}

\noindent where $\boldsymbol{\Omega}$ is a $p \times p$ model-implied covariance matrix and $\gamma$ is a vector of free parameters.  

> "All models are wrong, but some are useful"  
--- Box (1987, p. 424)

## What is Model Error?

Psychological phenomena are complex; no population covariance matrix will be perfectly represented by $\boldsymbol{\Omega}(\boldsymbol{\gamma})$ in practice.

Model error can be grouped into two basic categories (Meehl, 1990).

+ \alert{Incompleteness}: The model is too simple to adequately reflect reality (e.g., there are more common factors than are modeled). 
+ \alert{Falsity}: There are contradictions between the model and the world (e.g., non-linear relationships are modeled as linear).

## Representing Model Error

An population covariance matrix with model error can be represented by

\begin{equation}
\boldsymbol{\Sigma} = \boldsymbol{\Omega} + \mathbf{E},
\end{equation}

where $\mathbf{E}$ is a symmetric error matrix representing the effects of model error.

## Why Should We Care About Model Error?

Monte Carlo simulation studies that sample from $\boldsymbol{\Omega}$ (rather than $\boldsymbol{\Sigma}$) are likely to produce overly-optimistic results.

Simulation work has shown that model error can affect: 

+ Parameter estimation for exploratory factor analysis (Briggs, 2003).
+ Dimensionality identification with parallel analysis (Kracht, 2020).
+ Behavior of confidence regions and fungible parameter estimates for structural equation models (Pek, 2012).
+ ...And other statistical procedures (Beauducel, 2016; de Winter, 2016, Gnambs, 2016; Hsu, 2015; Trichtinger, 2020).

\alert{Problem}: How can we simulate $\boldsymbol{\Sigma}$ with "realistic" model error?

# Simulating Model Error

## Existing Model Error Methods

Three of the most prominent model error methods are:

1. Tucker, Koopman, and Linn (TKL; 1969)
2. Cudeck and Browne (CB; 1992)
3. Wu and Browne (WB; 2015)

<!-- The *ad hoc* methods of misspecifying the number of common factors by one or two factors, or misspecifying the relationships between observed and latent variables are not of interest here. -->

## The Tucker, Koopman, and Linn Method

The TKL method is based on the common factor analysis model for $k$ common factors:

\begin{equation}
\boldsymbol{\Omega} = \boldsymbol{\Lambda} \boldsymbol{\Phi} \boldsymbol{\Lambda}^\prime + \boldsymbol{\Psi},
\end{equation}

where  

+ $\boldsymbol{\Omega}_{p \times p}$: model-implied covariance matrix.
+ $\boldsymbol{\Lambda}_{p \times k}$: factor-pattern matrix.
+ $\boldsymbol{\Phi}_{k \times k}$: common factor covariance matrix.
+ $\boldsymbol{\Psi}_{p \times p}$: diagonal matrix containing the unique variances.

Let all common factors be standardized in the population so that $\boldsymbol{\Omega}$ has a unit diagonal (i.e., is a correlation matrix).  

## The Tucker, Koopman, and Linn Method

Model error is represented as the effect of numerous minor common factors such that $\mathbf{W}_{p \times q}$ is the matrix of minor factor loadings for the $q \succeq k$ minor common factors,

\begin{equation}
\boldsymbol{\Sigma} = \boldsymbol{\Lambda} \boldsymbol{\Phi} \boldsymbol{\Lambda}^\prime + \boldsymbol{\Psi} + \mathbf{WW}^\prime
\end{equation}


Minor common factors are \alert{"...far too many and far too minor to be retained in a factor analysis of empirical data"} (MacCallum, 2003, p. 135).

## The Tucker, Koopman, and Linn Method: User Parameters

Two user-specified parameters affect the characteristics of $\mathbf{W}$:

- $\nu_{\textrm{e}} \in [0, 1]$: Proportion of unique variance allocated to the minor common factors.  

- $\epsilon \in [0, 1]$: Controls how variance is distributed among the minor common factors. Values close to zero result in relatively equipotent minor factors whereas values of close to one result in error variance primarily being distributed to the first minor factor.

## The Tucker, Koopman, and Linn Method

### Advantages

+ Straightforward interpretation of model error arising from un-modeled minor common factors.
+ Quite flexible; two parameters ($\nu_{\textrm{e}}$ and $\epsilon$) to manipulate.
+ Relatively easy to implement.

### Disadvantages

+ Cannot be used for all types of covariance structure models (factor analysis models only).
+ No clear guidelines for reasonable/realistic values of $\nu_{\textrm{e}}$ and $\epsilon$.
+ No direct control of degree of model fit (in terms of e.g., RMSEA) as traditionally implemented.

## The Cudeck and Browne Method

Cudeck and Browne developed a model error method for any covariance structure model, $\boldsymbol{\Omega} = \boldsymbol{\Omega}(\boldsymbol{\gamma})$.

For a particular vector of model parameters $\boldsymbol{\gamma}_0$, let $\boldsymbol{\Sigma}_0 = \boldsymbol{\Omega}(\boldsymbol{\gamma}_0) + \mathbf{E}$

Their method seeks to find an $\mathbf{E}$ matrix such that

1. $F(\boldsymbol{\Sigma}_0, \boldsymbol{\Omega}(\boldsymbol{\gamma}))$ is minimized when $\boldsymbol{\gamma} = \boldsymbol{\gamma}_0$.
2. $F(\boldsymbol{\Sigma}_0, \boldsymbol{\Omega}(\boldsymbol{\gamma})) = \delta$ when $\boldsymbol{\gamma} = \boldsymbol{\gamma}_0$ for some user-specified $\delta$.

\vspace{10pt}

Here, $F(\boldsymbol{\Sigma}_0, \boldsymbol{\Omega}(\boldsymbol{\gamma}))$ is a discrepancy function (ML or OLS).

## The Cudeck and Browne Method

### Advantages

+ Adaptable to any covariance structure model.
+ Allows a target RMSEA value to be directly specified (because $\delta$ is related to RMSEA; more on that later).
+ No structural assumptions about $\mathbf{E}$; any suitable $\mathbf{E}$ matrix will do.

### Disadvantages

+ Can result in indefinite $\boldsymbol{\Sigma}$ matrices if $\delta$ is too large.
+ Relatively difficult to implement.
+ Inflexible; only one parameter to control.
+ Implies that $\boldsymbol{\gamma}_0$ will be perfectly recovered from a sample covariance matrix as sample size goes to $\infty$ (is this reasonable?).

## The Wu and Browne Method

Model error is considered to be a random effect due to differences between the operational population and some ideal population for which the theory is hypothesized.

Specifically, $\boldsymbol{\Sigma}$ is considered to be a random sample from an inverse-Wishart distribution such that

\begin{equation}
(\boldsymbol{\Sigma} | \boldsymbol{\Omega}) \sim W^{-1}_p(m \boldsymbol{\Omega}, m),
\end{equation}

where $m = 1/v$ is a continuous precision parameter such that $m > p - 1$.

\vspace{14pt}

> "[The ideal] population need not have an explicit empirical description. In this sense, the
general population is defined by the model rather than by its empirical nature."  
--- MacCallum and O'Hagan (2015, p. 605)

## The Wu and Browne Method

### Advantages

+ Adaptable to any covariance structure model.
+ Fast and relatively easy to implement.
+ Allows a target RMSEA value to be specified.

### Disadvantages

+ Inflexible; only one parameter to control.
+ Resulting RMSEA values are often not close to target values when target values are (relatively) large.
+ Possible RMSEA values limited by $m > p - 1$.
+ Based on a specific theory of model error; assumes that error-perturbed covariance matrices are distributed according to an inverse Wishart distribution.

## Evaluating Model Error: Fit Indices

Many population model fit indices have been used to quantify the discrepancy between:

+ $\boldsymbol{\Sigma}$ and $\boldsymbol{\Omega}$  
+ $\boldsymbol{\Sigma}$ and $\hat{\boldsymbol{\Omega}}$ (the implied covariance matrix from an analysis of $\boldsymbol{\Sigma}$)

### Absolute Fit Indices

- Root Mean Square Error of Approximation (RMSEA; Steiger, 1990)      
- Correlation Root Mean Square Residual (CRMR; Bollen, 1989; Ogasawara, 2001)

### Incremental Fit Indices

- Comparative Fit Index (CFI; Bentler, 1990)  
- Tucker-Lewis Index (TLI; Tucker & Lewis, 1973)  

## Evaluating Model Error: Disagreement Among Indices

Different model fit indices can lead to different qualitative interpretations of model fit when cut-off values are used to categorize model fit.

\alert{Example}: RMSEA($\boldsymbol{\Sigma}$, $\boldsymbol{\Omega}$) $= 0.04$; CFI($\boldsymbol{\Sigma}$, $\boldsymbol{\Omega}$) = $0.78$.  

- RMSEA values less than 0.05 generally represent good model fit.  
- CFI values less than 0.90 generally represent unacceptably poor model fit.  

\vspace{14pt}

> "[T]here is no such thing as a magical, single-number summary that says everything worth knowing about model fit."  
---Kline (2011, p. 193)

## Controlling the Amount of Model Error

Given that fit indices can lead to different qualitative interpretations of model fit, researchers should use and report multiple model fit indices in Monte Carlo simulation studies.

+ Can model error methods be used as-is or modified to produce $\boldsymbol{\Sigma}$ matrices with model-fit statistic values close to the target values? How effective are they in this task?
+ How do the model fit methods differ in terms of CFI, TLI, and SRMR/CRMR for error-perturbed covariance matrices, when holding RMSEA values approximately equal?

## TKL: Specifying the Amount of Model Error

### Problems

- There are no empirically-supported guidelines for appropriate values of $\nu_{\textrm{e}}$ and $\epsilon$.
- Choosing values of $\nu_{\textrm{e}}$ and $\epsilon$ that result in a specific model fit index value is difficult.
- Choosing values of $\nu_{\textrm{e}}$ and $\epsilon$ that result in multiple specific model fit index values (e.g., RMSEA and CFI) can be *very* difficult (sometimes impossible).

### Solution

- Create an optimization procedure to find values of $\nu_{\textrm{e}}$ and $\epsilon$ that give RMSEA and/or CFI values that are as close as possible to target values.

## TKL: Optimization Procedure (RMSEA & CFI)

Use the L-BFGS-B (Zhu et al., 1997) algorithm to minimize the function:

\begin{equation}
G(\nu_{\textrm{e}}, \epsilon) = b_1 \left[ \varepsilon - \varepsilon_\textrm{T} \right]^2 + b_2 \left[ CFI - \textrm{CFI}_{\textrm{T}} \right]^2 + \mathbf{1}_{\boldsymbol{W}} \lambda
\end{equation}

- $b_1$ and $b_2$: User-specified weights that sum to one.  
- $\varepsilon_\textrm{T}$: User-specified target RMSEA value.  
- $\textrm{CFI}_{\textrm{T}}$: User-specified target CFI value.  
- $\mathbf{1}_{\boldsymbol{W}}$: Indicator function that equals one if any minor factor has more than two factor loadings $\geq .3$ in absolute value.  
- $\lambda$: User-specified penalty.

## CB: Specifying the Amount of Model Error (RMSEA)

The CB method allows a user to generate an error-perturbed covariance matrix with a specified RMSEA value.

\begin{equation}
\delta = \varepsilon_\textrm{T} df,
\end{equation}
\noindent where $df$ denotes the model degrees of freedom.  

+ $\boldsymbol{\Sigma}$ can be indefinite if $\delta$ is too large.
+ If $\delta$ is large, $\theta_0$ might correspond to a saddle point.

## WB: Specifying the Amount of Model Error (RMSEA)

The error-perturbed covariance matrix $\boldsymbol{\Sigma}$ is sampled from:  

\begin{equation}
(\boldsymbol{\Sigma} | \boldsymbol{\Omega}) \sim W^{-1}_p(m \boldsymbol{\Omega}, m),
\end{equation}

The precision parameter, $m = 1/v$, is related to RMSEA such that $v \approx \varepsilon^2$.  

The approximation gets worse as $\varepsilon^2$ increases; simply using $m = 1 / \tilde{v}$ is unlikely to lead to RMSEA values close to $\varepsilon_\textrm{T}$ when $\varepsilon_\textrm{T}$ is not very small.

## WB: Fit a Regression Model for $v$

Find an appropriate value of $v$ such that RMSEA($\boldsymbol{\Sigma}, \boldsymbol{\Omega}$) $\approx \varepsilon_\textrm{T}$:  

\begin{enumerate}

\item Create a vector of $\tilde{v}$ values for $\varepsilon_\textrm{T}$ values in a reasonable range (e.g., 20 values between 0.01 and 0.095).  
\item For each value of $\tilde{v}$:
  \begin{itemize}
    \item Sample a number of covariance matrices (e.g., 50) from the corresponding inverse-Wishart distribution.
    \item Calculate the median RMSEA value for the sampled covariance matrices.
  \end{itemize}
\item Regress $\tilde{v}$ on the median RMSEA and squared median RMSE values.
\item Use the fitted model from Step 3 to find a value of $v$ that is likely to lead to error-perturbed covariance matrices with RMSEA values close to $\varepsilon_\textrm{T}$.

\end{enumerate}

## WB: Example

```{r wb-mod-plot, fig.align = "center", dpi = 800}
if (make_plots) {
  set.seed(123)
  
  reps <- 50
  NFac <- 5
  mod <- fungible::simFA(Model = list(NFac = NFac, NItemPerFac = 5), Seed = 123)
  target_rmsea <- seq(0.01, 0.095, length.out = 20)
  vtilde <- target_rmsea^2
  
  rmsea_vec <- numeric(reps)
  median_rmsea <- numeric(length(target_rmsea))
  
  for (i in seq_along(target_rmsea)) {
    for (rep in 1:reps) {
      Rwb <- noisemaker::wb(mod, target_rmsea = target_rmsea[i],
                            adjust_target = FALSE)
      rmsea_vec[rep] <- noisemaker::rmsea(Rwb, mod$Rpop, k = NFac)
    }
    median_rmsea[i] <- median(rmsea_vec)
  }
  
  wb_data <- data.frame(v = vtilde, median_rmsea = median_rmsea)
  
  ggplot(wb_data, aes(y = sqrt(v), x = median_rmsea)) +
    geom_point() +
    geom_smooth(method = lm, 
                formula = y ~ poly(x, 2), 
                se = FALSE, color = "darkorange", lty = 2, size = .75) +
    geom_abline(a = 0, b = 1, color = "gray") +
    theme_minimal() + 
    labs(x = latex2exp::TeX("median $\\epsilon$"),
         y = latex2exp::TeX("$\\sqrt{\\tilde{v}} = \\epsilon_\textrm{T}$"),
         title = latex2exp::TeX("Relationship between $\\sqrt{\\tilde{v}}$ and $\\epsilon$ for a 5-factor model"),
         caption = "The solid gray line indicates where the target RMSEA and median RMSEA values would be equal. \nThe dashed orange line indicates the predicted value of v given an RMSEA value.")
  
  ggsave(filename = "wb-plot.png",
         plot = last_plot(),
         dpi = 320,
         height = 4, 
         width = 5,
         scale = 1.1)
}

knitr::include_graphics(
  "wb-plot.png",
  dpi = 600
)
```

## Aims of the Proposed Study

Two main aims:

1. Determine how error-perturbed covariance matrices produced by the TKL, CB, and WB model error methods differ in terms of CFI, TLI, and SRMR when matched (approximately) on RMSEA.  
2. Determine how well (a) the proposed optimization procedure for controlling RMSEA and CFI with the TKL method and (b) the regression procedure for controlling RMSEA with the WB method work.

# Method

## Design Variables: Population Models

+ Population models with 1, 3, 5 or 10 major common factors.
+ Data sets with either 5 or 15 items per factor ($p \in [5, 15, 25, 45, 50, 75, 150]$).
+ Common factor correlations either 0.0 (orthogonal), 0.3, or 0.6.
+ Three factor loading structure types (simple structure): "Strong", "Moderate", and "Weak", corresponding to factor loadings of 0.8, 0.6, and 0.4 (Hair et al., 2018).

## Design Variables: Model Error

+ Model error methods
  + TKL (using target RMSEA, target CFI, and target RMSEA/CFI values; with and without constraints)
  + CB
  + WB
+ Model fit targets
  + $\varepsilon_\textrm{T} \in [0.025, 0.065, 0.090]$.
  + $\textrm{CFI}_{\textrm{T}} \in [0.99, 0.95, 0.90]$.
  + $\varepsilon_\textrm{T}$ and $\textrm{CFI}_{\textrm{T}}$ pairs correspond to very good, fair, and poor model fit (MacCallum et al., 2001; Myers et al., 2015).
 
Note that target CFI only affects the TKL (RMSEA/CFI) procedure.

## Design Variables: Summary

```{r count-conditions}
conditions <- expand.grid(
  factors = c(1,3,5,10),
  items = c(5, 15),
  factor_corr = c(0,.3,.6),
  loadings = c(0.4, 0.6, 0.8),
  model_fit = c("Very Good", "Fair", "Poor"),
  model_error_method = c("TKL-RMSEA", "TKL-CFI", "TKL-RMSEA-CFI",
                         "TKL-RMSEA-C", "TKL-CFI-C", "TKL-RMSEA-CFI-C",
                         "CB", "WB")
)

pop_mods <- expand.grid(
  factors = c(1,3,5),
  items = c(5, 15),
  factor_corr = c(0,.3,.6),
  loadings= c(0.4, 0.6, 0.8)
)

conditions <- dplyr::filter(conditions,
                     !(factors == 1 & factor_corr > 0))
pop_mods <- dplyr::filter(pop_mods,
                   !(factors == 1 & factor_corr > 0))
```

```{r study1-tab, message=F, warning=F}
study1_vars <- rbind(
  c("Factors" = "1, 3, 5, 10",
    "Items/Factor" = "5, 15",
    "Factor Correlation ($\\phi$)" = "0.0, 0.3, 0.6",
    "Loadings" = "0.4, 0.6, 0.8",
    "Target Model Fit" = "Very Good ($\\varepsilon_\\textrm{T} = 0.025$, $\\textrm{CFI}_{\\textrm{T}} = 0.99$),",
    " " = "Fair ($\\varepsilon_\\textrm{T} = 0.065$, $\\textrm{CFI}_{\\textrm{T}} = 0.95$),",
    "  " = "Poor ($\\varepsilon_\\textrm{T} = 0.090$, $\\textrm{CFI}_{\\textrm{T}} = 0.90$)",
    "Error Method" = "TKL (six variants), CB, WB")
)

study1_vars <- tibble::as_tibble(t(study1_vars),
                                 rownames = "Variable")

knitr::kable(
  x = study1_vars,
  booktabs = TRUE,
  caption = "Design Variables and Levels.",
  escape = FALSE,
  col.names = c("Variable", "Levels"),
  note = "$\\varepsilon_\\textrm{T}$ = Target RMSEA value.", 
)
```

## Study Design Variables: Summary

+ `r nrow(pop_mods)` (error-free) population models.
+ `r scales::comma(nrow(conditions))` crossed conditions.
+ 500 reps for all model-error methods.
+ $500 \times 1,440 = 720,000$ simulated $\boldsymbol{\Sigma}$ matrices.

## Study Design: Simulation Procedure

### Data generation

+ For each (error-free) population model, generate the model-implied correlation matrix ($\boldsymbol{\Omega}$).
+ For each model-implied correlation matrix:
  + Generate 500 error-perturbed covariance matrices ($\bSigma$) for each of the TKL, CB, and WB model-error methods at each $\varepsilon_\textrm{T}$ and $\textrm{CFI}_{\textrm{T}}$ value pair.
    
### Evaluation

For each error-perturbed correlation ($\bSigma$) matrix: 

+ Compute RMSEA, CFI, TLI, and CRMR for $\boldsymbol{\Sigma}$ and $\boldsymbol{\Omega}$ (and for $\boldsymbol{\Sigma}$ and $\hat{\boldsymbol{\Omega}}$).
+ Compute:

\begin{equation}
D = |\textrm{RMSEA}_{\textrm{obs}} - \textrm{RMSEA}_{\textrm{T}}| + |\textrm{CFI}_{\textrm{obs}} - \textrm{CFI}_{\textrm{T}}|
\end{equation}

# Results

## Section Overview

+ First topic
+ Second topic
+ Third topic

## Distribution of $\rmseaOmega$

```{r echo = FALSE, out.width = '95%', fig.align = 'center'}
knitr::include_graphics(here("img/rmsea_distributions.png"))
```

## Distribution of $\cfiOmega$

```{r echo = FALSE, out.width = '95%', fig.align = 'center'}
knitr::include_graphics(here("img/cfi_distributions.png"))
```

## Fit Index Agreement: $D$

```{r echo = FALSE, out.width = '95%', fig.align = 'center'}
knitr::include_graphics(here("img/d_plot.png"))
```

## Qualitative Fit Index Agreement

```{r echo = FALSE, out.width = '95%', fig.align = 'center'}
knitr::include_graphics(here("img/fit_index_agreement.png"))
```

# Backup Slides

## Population Model Fit Indices

\begin{equation}
\textrm{RMSEA} = \varepsilon = \sqrt{\frac{F_h}{df_h}},
\end{equation}

\begin{equation}
\textrm{CFI} = 1 - \frac{F_h}{F_b},
\end{equation}

\begin{equation}
\textrm{TLI} = 1 - \frac{F_h / df_h}{F_b / df_b}
\end{equation}

+ $F_h$ and $df_h$ denote the discrepancy function value and degrees of freedom for the full model.
+ $F_b$ and $df_b$ denote the discrepancy function value and degrees of freedom for the baseline (independence) model.

## Population Model Fit Indices

\begin{equation}
\textrm{SRMR} = \sqrt{ \frac{1}{p (p + 1) / 2} \sum_{i \leq j} \left(  \frac{\sigma_{ij} - \omega_{ij}}{\sqrt{\sigma_{ii} \sigma_{jj}}} \ \right) ^2 }
\end{equation}

\begin{equation}
\textrm{CRMR} = \sqrt{ \frac{1}{p (p - 1) / 2} \sum_{i < j} \left( \sigma_{ij} - \omega_{ij} \ \right) ^2 }
\end{equation}

+ $p$ is the number of observed variables.   
+ $\sigma_{ij}$ and $\omega_{ij}$ are the $i,j$th elements of $\boldsymbol{\Sigma}$ and $\boldsymbol{\Omega}$, respectively.  

## Local Optima

```{r fig.align='center', fig.width = 6}
knitr::include_graphics("local_optima.png", dpi = 800)
```

## Indefinite Matrices

```{r, echo = FALSE, out.width='85%', fig.align='center'}
knitr::include_graphics(here("img/cb_percent_indefinite.png"))
```

## L-BFGS-B Non-convergence

- Non-convergence only occurred when the $\TKLrmseacfi$ method was used.  
- Only 14 of 90,000 (<1%) of $\TKLrmseacfi$ cases failed to converge using L-BFGS-B.  

```{r echo = FALSE, out.width = '55%', fig.align='center'}
knitr::include_graphics(here("img/nonconverged_rmsea_cfi.png"))
```

## Major Minor Factors

```{r echo = FALSE, out.width = '90%', fig.align = 'center'}
knitr::include_graphics(here("img/major_minor_factors.png"))
```